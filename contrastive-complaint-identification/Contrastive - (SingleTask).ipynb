{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4762,"status":"ok","timestamp":1684685538002,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"O2bPVSPokXpd","outputId":"348700bc-5029-481d-9b47-7949118f74db"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print(device)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1684685538003,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"9Yw2Qc3tkalj"},"outputs":[],"source":["import torch\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13531,"status":"ok","timestamp":1684685551520,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"Z1tPm-BGkcoS","outputId":"7c8c62aa-5561-4337-e6ea-1f12ef737fac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"]}],"source":["!pip install transformers "]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1684685551522,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"QPbpFGyIkeLK"},"outputs":[],"source":["df = pd.read_csv('/content/Complaint data annotation (explain)_updated - cd (1).csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1684685551523,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"Vs8yd-Hgku7V","outputId":"b31485da-7de7-419d-a547-edefe7c9349c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['id', 'tweet', 'label', 'domain', 'sentiment', 'emotion', 'Severity',\n","       'Explain'],\n","      dtype='object')"]},"metadata":{},"execution_count":5}],"source":["df.keys()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1684685551523,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"-sMinYbXkyFr","outputId":"d85ec722-30c4-4e29-a29b-05dcd9a83f70"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                              tweet  label   domain  \\\n","0   1  @FC_HELP can I return online purchases to a Ho...      0  apparel   \n","1   2  @FC_Help Hi - I'm writing a piece for MSN Him ...      0  apparel   \n","2   3                @FC_Help   i need to check my order      0  apparel   \n","3   4  @FC_Help I need to get in contact with someone...      1  apparel   \n","4   5  @FC_Help How can I get a hold of you so we can...      0  apparel   \n","\n","  sentiment emotion  Severity  \\\n","0   Neutral   other         0   \n","1  Positive   other         0   \n","2   Neutral   other         0   \n","3   Neutral   other         1   \n","4  Negative   other         0   \n","\n","                                             Explain  \n","0  can I return online purchases to a House of Fr...  \n","1  Hi - I'm writing a piece for MSN Him and wonde...  \n","2                           i need to check my order  \n","3  I need to get in contact with someone regardin...  \n","4  How can I get a hold of you so we can discuss ...  "],"text/html":["\n","  <div id=\"df-d1c74eba-8823-4987-841c-fee5e0e6261c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>label</th>\n","      <th>domain</th>\n","      <th>sentiment</th>\n","      <th>emotion</th>\n","      <th>Severity</th>\n","      <th>Explain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>@FC_HELP can I return online purchases to a Ho...</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Neutral</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>can I return online purchases to a House of Fr...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>@FC_Help Hi - I'm writing a piece for MSN Him ...</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Positive</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>Hi - I'm writing a piece for MSN Him and wonde...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>@FC_Help   i need to check my order</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Neutral</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>i need to check my order</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>@FC_Help I need to get in contact with someone...</td>\n","      <td>1</td>\n","      <td>apparel</td>\n","      <td>Neutral</td>\n","      <td>other</td>\n","      <td>1</td>\n","      <td>I need to get in contact with someone regardin...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>@FC_Help How can I get a hold of you so we can...</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Negative</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>How can I get a hold of you so we can discuss ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1c74eba-8823-4987-841c-fee5e0e6261c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d1c74eba-8823-4987-841c-fee5e0e6261c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d1c74eba-8823-4987-841c-fee5e0e6261c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1684685551524,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"2foIDP1gmXDF"},"outputs":[],"source":["domain_dict = {\n","    \"other\" : 0,\n","    \"services\" : 1,\n","    \"random_reply\" : 2,\n","    \"software\" : 3,\n","    \"retail\" : 4,\n","    \"random_tweet\" : 5,\n","    \"transport\" : 6,\n","    \"cars\" : 7,\n","    \"food\" : 8,\n","    \"apparel\" : 9,\n","    \"electronics\" : 10\n","}\n","\n","# note to take string lower\n","senti_dict = {\n","    'negative' : 0,\n","    'positive' : 1,\n","    'neutral' : 2\n","}\n","\n","emo_dict = {\n","    'sadness' : 0, \n","    'joy' : 1, \n","    'other' : 2, \n","    'anger' : 3, \n","    'disgust' : 4, \n","    'surprise' : 5, \n","    'fear' : 6\n","}"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1684685551525,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"CVP51OEwnMzu"},"outputs":[],"source":["label = []\n","domain = []\n","emotion = []\n","sentiment = []\n","severity = []\n","explain = []\n","\n","for i in range(len(df)):\n","  if (pd.isna(df['label'][i]) or pd.isna(df['domain'][i]) or pd.isna(df['emotion'][i]) or pd.isna(df['sentiment'][i]) or pd.isna(df['Severity'][i]) or pd.isna(df['Explain'][i])):\n","    continue\n","  label.append(df['label'][i])\n","  domain.append(domain_dict[df['domain'][i]])\n","  emotion.append(emo_dict[df['emotion'][i]])\n","  sentiment.append(senti_dict[(df['sentiment'][i]).lower()])\n","  severity.append(df['Severity'][i])\n","  explain.append(df['Explain'][i])"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1082,"status":"ok","timestamp":1684685552586,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"8m6kdXgPqCmj"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","label_train, label_test, domain_train, domain_test, emotion_train, emotion_test, sentiment_train, sentiment_test, severity_train, severity_test, explain_train, explain_test = train_test_split(label, domain, emotion, sentiment, severity, explain, test_size = 0.2, random_state = 42, shuffle = True)\n","label_train, label_val, domain_train, domain_val, emotion_train, emotion_val, sentiment_train, sentiment_val, severity_train, severity_val, explain_train, explain_val = train_test_split(label_train, domain_train, emotion_train, sentiment_train, severity_train, explain_train, test_size = 0.2, random_state = 42, shuffle = True)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["34efad8341dc4da9a865b874e8a2d167","136c26411dec458499216481cb3f122f","f5f09eac874f4428beee6a46e930c164","78bd5c8f544d4e69a38f5694d1bce4a4","a48e6d1cccac4e388f4262db46ec3bec","81d6acd8849e4818bc186b14e38fcfcb","d8b05aba431d489080d0f42dd1dd53b0","c105c72672c24fb7a0170a9afc764eb4","aff024647e2e4371984e148e9bdb3cad","3ead9659773345f895f8da4902c5f4eb","4e51b41634294c8b80621fd0fcae1339","c4a9e6826ec0406cae65eb343738fd50","a20bfb511c2a499bac810ddaa2371dc5","1f40fe82a571455799620f061c97694b","d0b9b034c10e425784028eea56473c92","128bfdbe47404cf8bbdff82138654ffa","90668c3d54b641f48ad95a2587959a30","031d81ded5a64e5bb81e9e8b9bdb4734","bb650d4cbc5343d09c9700b840fb9c26","ec31b21778a241309cdef34d4a7f43cd","d7cf0b8a0f1e475b91f283e661d3d36c","bfbdabbeda8544038ea8a82d7abc425e","d829aed0cf1744979e8c092bb808ab61","1168f3c0765b45fea2acd667fac9a693","bd09d71671d04d809a970f8f3b4542fd","38ad300a04884edeabf8a2af24e46548","031762f4e582439c903e5b083da4bdbd","bfdeb2f1b98143b3beabb8d6afae237c","d9e1fc6ae0f845c3b1f9c562b770a649","4612599df8c24b6da2cd1823a190335f","19d18d44bbad455e86e1992c75034084","7732f08c10c948fe9b8839853d0b029e","0a363fc0629449948e437458648e22dd"]},"executionInfo":{"elapsed":2982,"status":"ok","timestamp":1684685555564,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"f0w5ajsPrGSm","outputId":"84b6b7cd-7604-4883-d013-76801fc42da2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34efad8341dc4da9a865b874e8a2d167"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4a9e6826ec0406cae65eb343738fd50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d829aed0cf1744979e8c092bb808ab61"}},"metadata":{}}],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","def preprocess_data(text):\n","  g_input_ids = []\n","  g_attention_mask = []\n","\n","  for line in text:\n","    inputs = tokenizer(line, return_tensors=\"pt\")\n","\n","    input_ids = inputs[\"input_ids\"]\n","    attention_mask = inputs[\"attention_mask\"]\n","\n","    size = input_ids.shape[1]\n","\n","    if size < 60:\n","      input_ids = torch.cat((input_ids, torch.zeros(1, 60-size)), dim = 1)\n","      attention_mask = torch.cat((attention_mask, torch.zeros(1, 60-size)), dim = 1)\n","    else:\n","      input_ids = input_ids[:, :60]\n","      attention_mask = attention_mask[:, :60]\n","    \n","    # Why we use np.array()\n","    g_input_ids.append(np.array(input_ids.reshape(-1)))\n","    g_attention_mask.append(np.array(attention_mask.reshape(-1)))\n","\n","  g_input_ids = torch.tensor(g_input_ids)\n","  g_attention_mask = torch.tensor(g_attention_mask)\n","\n","  return g_input_ids, g_attention_mask"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1873,"status":"ok","timestamp":1684685557434,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"G87hIDIdyZa1","outputId":"b46832e6-8db6-4f55-ff9b-1c4637e73579"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-eb1c066b164e>:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  g_input_ids = torch.tensor(g_input_ids)\n"]}],"source":["input_ids_train, attention_mask_train = preprocess_data(explain_train)\n","input_ids_val, attention_mask_val = preprocess_data(explain_val)\n","input_ids_test, attention_mask_test = preprocess_data(explain_test)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":667,"status":"ok","timestamp":1684685558098,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"bBQt0Q6iyaHl"},"outputs":[],"source":["class Complaint_dataset():\n","  def __init__(self, input_ids, attention_mask, label, domain, emotion, sentiment, severity):\n","    self.input_ids = input_ids\n","    self.attention_mask = attention_mask\n","    self.label = label\n","    self.domain = domain\n","    self.emotion = emotion\n","    self.sentiment = sentiment\n","    self.severity = severity\n","  def __len__(self):\n","    return len(self.input_ids)\n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","      idx = idx.tolist()\n","    \n","    sample = {\n","        \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","        \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n","        \"label\" : torch.tensor(self.label[idx]).long().to(device),\n","        \"domain\" : torch.tensor(self.domain[idx]).long().to(device),\n","        \"emotion\" : torch.tensor(self.emotion[idx]).long().to(device),\n","        \"sentiment\" : torch.tensor(self.sentiment[idx]).long().to(device),\n","        \"severity\" : torch.tensor(self.severity[idx]).long().to(device)\n","    }\n","\n","    return sample"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1684685558099,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"vbPbUUxNymMu"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","complaint_train = Complaint_dataset(input_ids_train, attention_mask_train, label_train, domain_train, emotion_train, sentiment_train, severity_train)\n","train_dataloader = DataLoader(complaint_train, batch_size = 32, shuffle = False)\n","\n","complaint_val = Complaint_dataset(input_ids_val, attention_mask_val, label_val, domain_val, emotion_val, sentiment_val, severity_val)\n","val_dataloader = DataLoader(complaint_val, batch_size = 32, shuffle = False)\n","\n","complaint_test = Complaint_dataset(input_ids_test, attention_mask_test, label_test, domain_test, emotion_test, sentiment_test, severity_test)\n","test_dataloader = DataLoader(complaint_test, batch_size = 32, shuffle = False)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1684685558099,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"DknUGhh90DCl"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers import BertTokenizer, BertModel\n","\n","# What is super(Complaint) doing and why the name __init__() as such\n","# Practise OOPS\n","\n","class Complaint(nn.Module):\n","  def __init__(self):\n","    super(Complaint, self).__init__()\n","    self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n","    self.complaint = nn.Linear(768, 2)\n","    self.severity = nn.Linear(768, 5)\n","  def forward(self, input_ids, attention_mask):\n","    data = self.bert_model(input_ids = input_ids, attention_mask = attention_mask).pooler_output\n","    Complaint = self.complaint(data)\n","    Severity = self.severity(data)\n","    return data, Complaint, Severity"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1684685558099,"user":{"displayName":"meachine learning","userId":"02615647607236970242"},"user_tz":-330},"id":"P1Baxi2x-YvK"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","class SupConLoss(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.xent_loss = nn.CrossEntropyLoss()\n","        self.alpha = 0.5\n","        self.temp = 0.1\n","\n","    def nt_xent_loss(self, anchor, target, labels):\n","        with torch.no_grad():\n","            labels = labels.unsqueeze(-1)\n","            mask = torch.eq(labels, labels.transpose(0, 1))\n","            mask = mask ^ torch.diag_embed(torch.diag(mask))\n","\n","        anchor_dot_target = torch.einsum('bd,cd->bc', anchor, target) / self.temp\n","\n","        anchor_dot_target = anchor_dot_target - torch.diag_embed(torch.diag(anchor_dot_target))\n","\n","        logits_max, _ = torch.max(anchor_dot_target, dim=1, keepdim=True)\n","        logits = anchor_dot_target - logits_max.detach()\n","\n","        exp_logits = torch.exp(logits)\n","\n","        logits = logits * mask\n","        log_prob = logits - torch.log(exp_logits.sum(dim=1, keepdim=True) + 1e-12)\n","\n","        mask_sum = mask.sum(dim=1)\n","        mask_sum = torch.where(mask_sum == 0, torch.ones_like(mask_sum), mask_sum)\n","\n","        pos_logits = (mask * log_prob).sum(dim=1) / mask_sum.detach()\n","        loss = -1 * pos_logits.mean()\n","        return loss\n","\n","    def forward(self, output, predicted, targets):\n","        normed_output = F.normalize(output, dim=-1)\n","        ce_loss = (1 - self.alpha) * self.xent_loss(predicted, targets)\n","        cl_loss = self.alpha * self.nt_xent_loss(normed_output, normed_output, targets)\n","        return cl_loss + ce_loss"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":884,"referenced_widgets":["75db5e46496041468a0041246403c39d","29130bc856a54001ab4400937683dc97","9788cfb4d9f6458bbdfe16efd53c8588","c2f7ead9134346d699c5afaa52de717f","eb572ec94c0447ddace9f7f0826663e5","4b9fbbb3ab5b4443a0276f2f1b85ad0f","dd46806bf1e44eea87d623116c719004","c3675a3226c546bca99c776cbda6e4e0","95c0c699614a488da9a4660d511f8c36","f950ea9b1e9b4a9cb7c803085327f7cc","f31a0c3858d04bfd9b81d39ee7bbffb9"]},"id":"wkXWdsQY7Qm2","executionInfo":{"status":"ok","timestamp":1684688919938,"user_tz":-330,"elapsed":3361848,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}},"outputId":"6327aa7f-274b-4edc-97c5-d57e82ce77dc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75db5e46496041468a0041246403c39d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","<ipython-input-12-aa0febf124e5>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","<ipython-input-12-aa0febf124e5>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n"]},{"output_type":"stream","name":"stdout","text":["Epoch : 1\n","Validation loss : 9.070812791585922\n","Epoch : 2\n","Validation loss : 8.954358905553818\n","Epoch : 3\n","Validation loss : 8.949107885360718\n","Epoch : 4\n","Validation loss : 9.194403737783432\n","Epoch : 5\n","Validation loss : 9.169870257377625\n","Epoch : 6\n","Validation loss : 9.19484692811966\n","Epoch : 7\n","Validation loss : 9.161197423934937\n","Epoch : 8\n","Validation loss : 9.175122395157814\n","Epoch : 9\n","Validation loss : 9.17286904156208\n","Epoch : 10\n","Validation loss : 9.18054684996605\n","Epoch : 11\n","Validation loss : 9.156481623649597\n","Epoch : 12\n","Validation loss : 9.162368789315224\n","Epoch : 13\n","Validation loss : 9.158236756920815\n","Epoch : 14\n","Validation loss : 9.155893877148628\n","Epoch : 15\n","Validation loss : 9.166744083166122\n","Epoch : 16\n","Validation loss : 9.167286545038223\n","Epoch : 17\n","Validation loss : 9.153554305434227\n","Epoch : 18\n","Validation loss : 9.15884605050087\n","Epoch : 19\n","Validation loss : 9.152196019887924\n","Epoch : 20\n","Validation loss : 9.15878076851368\n"]}],"source":["complaint_model = Complaint()\n","complaint_model = complaint_model.to(device)\n","complaint_model.train()\n","\n","loss_func = SupConLoss()\n","optimizer = torch.optim.Adam(complaint_model.parameters(), lr = 1e-5, weight_decay = 0)\n","epochs = 20\n","min_val_loss = 20\n","\n","complaint_model.train()\n","\n","for i in range(epochs):\n","\n","  for data in train_dataloader:\n","    complaint_model.zero_grad()\n","    comp_train = data[\"label\"].to(device)\n","    sev_train = data[\"severity\"].to(device)\n","    emo_train = data[\"emotion\"].to(device)\n","    senti_train = data[\"sentiment\"].to(device)\n","    embed, comp_out, sev_out = complaint_model.forward(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device))\n","\n","    loss_train = loss_func(embed, comp_out, comp_train) + loss_func(embed, sev_out, sev_train)\n","    loss_train.backward()\n","    optimizer.step()\n","\n","    complaint_model.eval()\n","\n","    with torch.no_grad():\n","      total_loss_val = 0\n","      for data in val_dataloader:\n","        comp_val = data[\"label\"].to(device)\n","        sev_val = data[\"severity\"].to(device)\n","        emo_val = data[\"emotion\"].to(device)\n","        senti_val = data[\"sentiment\"].to(device)\n","        embed_val, comp_val_out, sev_val_out = complaint_model(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device))\n","\n","        val_loss = loss_func(embed_val, comp_val_out, comp_val) + loss_func(embed_val, sev_val_out, sev_val)\n","\n","        total_val = comp_val.size(0)\n","        total_loss_val += val_loss.item()\n","\n","      val_loss = total_loss_val / total_val\n","\n","    if ((min_val_loss-val_loss) > 1e-4):\n","      min_val_loss = val_loss\n","      torch.save(complaint_model.state_dict(), \"bert_model.pt\")\n","\n","  print(f\"Epoch : {i+1}\")\n","  print(f\"Validation loss : {val_loss}\")\n","\n","  complaint_model.load_state_dict(torch.load(\"bert_model.pt\"))"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"h1NLvSBHHVvP","executionInfo":{"status":"ok","timestamp":1684688919941,"user_tz":-330,"elapsed":46,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"outputs":[],"source":["from sklearn.metrics import *"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"-vcgpzrUNKQ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684688927234,"user_tz":-330,"elapsed":7304,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}},"outputId":"1cb7053f-a2f4-488a-dcc4-bc2d139ef031"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.4\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Mnt4YzqaUxgC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684688930498,"user_tz":-330,"elapsed":3276,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}},"outputId":"eb7dc9ae-c56f-4bcb-d667-b76d3c8d79f5"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-aa0febf124e5>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","<ipython-input-12-aa0febf124e5>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n"]},{"output_type":"stream","name":"stdout","text":["comp_test_accuracy : 0.8623188138008118\n","comp_test_precision : 0.8482142686843872\n","comp_test_f1 : 0.800000011920929\n","comp_test_recall : 0.7569721341133118\n","sev_test_accuracy : 0.2224343717098236\n","sev_test_precision : 0.2563333511352539\n","sev_test_f1 : 0.19622500240802765\n","sev_test_recall : 0.2224343717098236\n"]}],"source":["from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryF1Score, BinaryRecall\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassF1Score, MulticlassRecall\n","\n","comp_accuracy = BinaryAccuracy()\n","comp_precision = BinaryPrecision()\n","comp_f1 = BinaryF1Score()\n","comp_recall = BinaryRecall() \n","\n","sev_accuracy = MulticlassAccuracy(num_classes=5)\n","sev_precision = MulticlassPrecision(num_classes=5)\n","sev_f1 = MulticlassF1Score(num_classes=5)\n","sev_recall = MulticlassRecall(num_classes=5)\n","\n","with torch.no_grad():\n","    for data in test_dataloader:\n","      lab_comp = data[\"label\"]\n","      lab_sev = data[\"severity\"]\n","\n","      _, comp_out, sev_out = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"])\n","\n","      _, pred_comp = torch.max(comp_out.data,1)\n","      _, pred_sev = torch.max(sev_out.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu()) \n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      sev_accuracy.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_precision.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_f1.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_recall.update(pred_sev.cpu(), lab_sev.cpu())\n","\n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute() \n","\n","    sev_test_accuracy = sev_accuracy.compute()\n","    sev_test_precision = sev_precision.compute()\n","    sev_test_f1 = sev_f1.compute()\n","    sev_test_recall = sev_recall.compute()\n","\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\") \n","\n","    print(f\"sev_test_accuracy : {sev_test_accuracy}\")\n","    print(f\"sev_test_precision : {sev_test_precision}\")\n","    print(f\"sev_test_f1 : {sev_test_f1}\")\n","    print(f\"sev_test_recall : {sev_test_recall}\") "]},{"cell_type":"code","source":["embed_input = \"bert\"\n","bitmask_input = \"comp+sent\"\n","hid_size = 150"],"metadata":{"id":"LqopyuVhTXZq","executionInfo":{"status":"ok","timestamp":1684689856012,"user_tz":-330,"elapsed":6,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["  bitmasks = {\n","    \"comp\" : 1,\n","    \"sent\" : 2,\n","    \"emo\" : 4,\n","    \"comp+sent\" : 3,\n","    \"comp+emo\" : 5,\n","    \"comp+sev\" : 9,\n","    \"comp+sent+emo\" : 7,\n","    \"comp+sent+sev\" : 11,\n","    \"comp+emo+sev\" : 13,\n","    \"comp+emo+sev+sent\" : 15\n","}\n","\n","embeds = {\n","    \"bert\" : \"bert-base-uncased\",\n","    \"roberta\" : \"roberta-base\"\n","}"],"metadata":{"id":"2nqf3Ub2Tb2_","executionInfo":{"status":"ok","timestamp":1684689859029,"user_tz":-330,"elapsed":3,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["learning_rate = 1e-5\n","epochs = 20\n","min_val_loss = 10"],"metadata":{"id":"mihhuYG_TiF7","executionInfo":{"status":"ok","timestamp":1684689862194,"user_tz":-330,"elapsed":3,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["class complaint(nn.Module):\n","  def __init__(self, hidden_size, bitmask, embedding):\n","    super(complaint, self).__init__()\n","    self.emb_model = AutoModel.from_pretrained(embedding)\n","    self.dropout = nn.Dropout(p = 0.5)\n","    self.hidden = nn.Linear(768, hidden_size)\n","    self.comp = nn.Linear(hidden_size, 2) #Complaint Output_Size = 2\n","    self.sent = nn.Linear(hidden_size, 3) #Sentiment Output_Size = 3\n","    self.sev = nn.Linear(hidden_size, 5) #Severity Level Output_Size = 5\n","    self.emo = nn.Linear(hidden_size, 7) #Emotional Level Output_Size = 7\n","    self.bitmask = bitmask\n","\n","  def forward_comp(self, x):\n","    out = self.comp(x)\n","    return out\n","  \n","  def forward_sent(self, x):\n","    out = self.sent(x)\n","    return out\n","  \n","  def forward_sev(self, x):\n","    out = self.sev(x)\n","    return out\n","  \n","  def forward_emo(self, x):\n","    out = self.emo(x)\n","    return out\n","\n","  def forward(self, input_ids, attention_mask, bitmask):\n","    data = self.dropout(self.emb_model(input_ids=input_ids, attention_mask=attention_mask).pooler_output)\n","    out = self.hidden(data)\n","    if (bitmask == bitmasks[\"comp\"]):\n","      out = self.forward_comp(out)\n","      return out\n","    \n","    if (bitmask == bitmasks[\"sent\"]):\n","      out = self.forward_sent(out)\n","      return out\n","    \n","    if (bitmask == bitmasks[\"emo\"]):\n","      out = self.forward_emo(out)\n","      return out\n","\n","    elif (bitmask == bitmasks[\"comp+sent\"]):\n","      out1 = self.forward_comp(out)\n","      out2 = self.forward_sent(out)\n","      return out1, out2\n","    elif(bitmask == bitmasks[\"comp+emo\"]):\n","      out1 = self.forward_comp(out)\n","      out2 = self.forward_emo(out)\n","      return out1, out2\n","    elif(bitmask == bitmasks[\"comp+sev\"]):\n","      out1 = self.forward_comp(out)\n","      out2 = self.forward_sev(out)\n","      return out1, out2\n","    elif(bitmask == bitmasks[\"comp+sent+emo\"]):\n","      out1 = self.forward_comp(out)\n","      out2 = self.forward_sent(out)\n","      out3 = self.forward_emo(out)\n","      return out1, out2, out3\n","    elif(bitmask == bitmasks[\"comp+sent+sev\"]):\n","      out1 = self.forward_comp(out)\n","      out2 = self.forward_sent(out)\n","      out3 = self.forward_sev(out)\n","      return out1, out2, out3\n","    elif(bitmask == bitmasks[\"comp+emo+sev\"]):\n","      out1 = self.forward_comp(out)\n","      out2 = self.forward_emo(out)\n","      out3 = self.forward_sev(out)\n","      return out1, out2, out3\n","    elif(bitmask == bitmasks[\"comp+emo+sev+sent\"]):\n","      out1 = self.forward_comp(out)\n","      out2 = self.forward_emo(out)\n","      out3 = self.forward_sev(out)\n","      out4 = self.forward_sent(out)\n","      return out1, out2, out3, out4"],"metadata":{"id":"OCZE_biUTiCe","executionInfo":{"status":"ok","timestamp":1684689865763,"user_tz":-330,"elapsed":2,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["df = pd.read_excel(\"/content/aspect_complain_formatted.xlsx\", \"new-FINCORP\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P61xf0zaTiAA","executionInfo":{"status":"ok","timestamp":1684689871822,"user_tz":-330,"elapsed":1873,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}},"outputId":"0ca497ea-3ed8-45b9-a0a2-accc2ff4233c"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n","  warn(msg)\n"]}]},{"cell_type":"code","source":["doc = []\n","label = []\n","\n","label_number = {\n","    \"comp\" : 0,\n","    \"sent\" : 1,\n","    \"sev\" : 2,\n","    \"emo\" : 3\n","}\n","\n","sent_num = {\n","    \"positive\" : 2,\n","    \"neutral\" : 1,\n","    \"negative\" : 0\n","}\n","\n","sev_num = {\n","    \"accusation\" : 0,\n","    \"blame\" : 1,\n","    \"disapproval\" : 2,\n","    \"no explicit reproach\" : 3,\n","    \"non-complaint\" : 4\n","}\n","\n","emo_num = {\n","    \"anger\" : 0,\n","    \"disgust\" : 1,\n","    \"fear\" : 2,\n","    \"happiness\" : 3,\n","    \"other\" : 4,\n","    \"sadness\" : 5,\n","    \"surprise\" : 6\n","}\n","\n","for i in range(len(df)):\n","  doc.append((df[\"Complaint/ Opinion\"])[i])\n","  temp = []\n","  temp.append((df[\"Over-all_Complaint Label\"])[i])\n","  temp.append(sent_num[((df[\"Sentiment\"])[i]).lower()])\n","  temp.append(sev_num[((df[\"Severity level\"])[i]).lower()])\n","  temp.append(emo_num[((df[\"Emotion\"])[i]).lower()])\n","  label.append(temp)\n","\n","doc_tr, doc_test, label_tr, label_test = train_test_split(doc, label, test_size=0.2, random_state = 42, shuffle=True)\n","doc_train, doc_val, label_train, label_val = train_test_split(doc_tr,label_tr, test_size=0.125, random_state = 42, shuffle=True)"],"metadata":{"id":"IQv8rba6Th8p","executionInfo":{"status":"ok","timestamp":1684689876280,"user_tz":-330,"elapsed":825,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModel\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from torch.utils.data import DataLoader"],"metadata":{"id":"goGll-F7WWsS","executionInfo":{"status":"ok","timestamp":1684690009857,"user_tz":-330,"elapsed":635,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(embeds[embed_input])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["5f7ecc00b7c849e6aa691cb6fa0c5192","a2243b9cff9746148946b0a72cccb565","0436bb0db94f4b67866c3ca08f37025b","156292e02aee4d21988b31434941531f","8a737a87594e484a9ba5b83b56d7c99b","f37cdde5a690485a83b0617fe4eebf34","cff04eb19684458481c68a2e6e9228f6","22b960578b1244ffac80c5e0eafa45ba","ce78576ebfe34f8eac35e14b5f17cfc7","e07b09a5cce24f8b8731edb30dda2b59","52961b4ffcd542b3ba67c8d84969374b"]},"id":"jy_oL_M3Th5z","executionInfo":{"status":"ok","timestamp":1684690014586,"user_tz":-330,"elapsed":1303,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}},"outputId":"8e607b5d-7c25-40ac-9150-7098433c7a07"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f7ecc00b7c849e6aa691cb6fa0c5192"}},"metadata":{}}]},{"cell_type":"code","source":["def preprocess_data(doc):\n","  \n","  g_input_ids = []\n","  g_attention_mask = []\n","  \n","  for x in doc:\n","    inputs = tokenizer(x, return_tensors=\"pt\")\n","\n","    input_ids = inputs[\"input_ids\"]\n","    attention_mask = inputs[\"attention_mask\"]\n","\n","    size = input_ids.shape[1]\n","\n","    if size < 60:\n","      input_ids = torch.cat((input_ids, torch.zeros(1, 60 - size)), dim=1)\n","      attention_mask = torch.cat((attention_mask, torch.zeros(1, 60 - size)), dim=1)\n","    else:\n","      input_ids = input_ids[:, :60]\n","      attention_mask = attention_mask[:, :60]\n","    \n","    g_input_ids.append(np.array(input_ids.reshape(-1)))\n","    g_attention_mask.append(np.array(attention_mask.reshape(-1)))\n","  \n","  g_input_ids = torch.tensor(g_input_ids)\n","  g_attention_mask = torch.tensor(g_attention_mask)\n","\n","  return g_input_ids, g_attention_mask"],"metadata":{"id":"6gmR9ZoHThpZ","executionInfo":{"status":"ok","timestamp":1684690044811,"user_tz":-330,"elapsed":588,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["input_ids_train,attention_mask_train = preprocess_data(doc_train)\n","input_ids_val, attention_mask_val = preprocess_data(doc_val)\n","input_ids_test, attention_mask_test = preprocess_data(doc_test)"],"metadata":{"id":"bdzflNkCThJb","executionInfo":{"status":"ok","timestamp":1684690050905,"user_tz":-330,"elapsed":3598,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["class complaint_dataset(torch.utils.data.Dataset):\n","  def __init__(self, g_input_ids, g_attention_mask, label_comp, label_sent, label_sev, label_emo):\n","    self.input_ids = g_input_ids\n","    self.attention_mask = g_attention_mask\n","    self.label_comp = label_comp\n","    self.label_sent = label_sent\n","    self.label_sev = label_sev\n","    self.label_emo = label_emo\n","  \n","  def __len__(self):\n","    return len(self.label_comp)\n","  \n","  def __getitem__(self, idx):\n","\n","    if torch.is_tensor(idx):\n","      idx = idx.tolist()\n","    \n","    sample = {\n","        # \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","        # \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n","        # \"label_comp\" : torch.tensor(self.label_comp[idx]).long().to(device),\n","        # \"label_sent\" : torch.tensor(self.label_sent[idx]).long().to(device),\n","        # \"label_sev\" : torch.tensor(self.label_sev[idx]).long().to(device),\n","        # \"label_emo\" : torch.tensor(self.label_emo[idx]).long().to(device)\n","\n","        \"input_ids\" : torch.tensor(self.input_ids[idx]).long(),\n","        \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long(),\n","        \"label_comp\" : torch.tensor(self.label_comp[idx]).long(),\n","        \"label_sent\" : torch.tensor(self.label_sent[idx]).long(),\n","        \"label_sev\" : torch.tensor(self.label_sev[idx]).long(),\n","        \"label_emo\" : torch.tensor(self.label_emo[idx]).long()\n","    }\n","\n","    return sample\n"],"metadata":{"id":"QpvBgePYT8Mt","executionInfo":{"status":"ok","timestamp":1684690050906,"user_tz":-330,"elapsed":5,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["train_comp = []\n","train_sent = []\n","train_sev = []\n","train_emo = []\n","val_comp = []\n","val_sent = []\n","val_sev = []\n","val_emo = []\n","test_comp = []\n","test_sent = []\n","test_sev = []\n","test_emo = []\n","\n","for x in label_train:\n","  train_comp.append(x[0])\n","  train_sent.append(x[1])\n","  train_sev.append(x[2])\n","  train_emo.append(x[3])\n","\n","for x in label_val:\n","  val_comp.append(x[0])\n","  val_sent.append(x[1])\n","  val_sev.append(x[2])\n","  val_emo.append(x[3])\n","\n","for x in label_test:\n","  test_comp.append(x[0])\n","  test_sent.append(x[1])\n","  test_sev.append(x[2])\n","  test_emo.append(x[3])"],"metadata":{"id":"ULUAuWDbT8Jv","executionInfo":{"status":"ok","timestamp":1684690052073,"user_tz":-330,"elapsed":5,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["complaint_train = complaint_dataset(input_ids_train, attention_mask_train, train_comp, train_sent, train_sev, train_emo)\n","train_dataloader = DataLoader(complaint_train, batch_size = 32, shuffle = False)\n","\n","complaint_val = complaint_dataset(input_ids_val, attention_mask_val, val_comp, val_sent, val_sev, val_emo)\n","val_dataloader = DataLoader(complaint_val, batch_size = 32 ,shuffle = False)\n","\n","complaint_test = complaint_dataset(input_ids_test, attention_mask_test, test_comp, test_sent, test_sev, test_emo)\n","test_dataloader = DataLoader(complaint_test, batch_size = 32, shuffle = False)"],"metadata":{"id":"mTYDIbLjT8HA","executionInfo":{"status":"ok","timestamp":1684690054806,"user_tz":-330,"elapsed":3,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["class CELoss(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.xent_loss = nn.CrossEntropyLoss()\n","\n","    def forward(self, outputs, targets):\n","        return self.xent_loss(outputs, targets)\n","\n","\n","class SupConLoss(nn.Module):\n","\n","    def __init__(self, alpha, temp):\n","        super().__init__()\n","        self.xent_loss = nn.CrossEntropyLoss()\n","        self.alpha = alpha\n","        self.temp = temp\n","\n","    def nt_xent_loss(self, anchor, target, labels):\n","        with torch.no_grad():\n","            labels = labels.unsqueeze(-1)\n","            mask = torch.eq(labels, labels.transpose(0, 1))\n","            # delete diag elem\n","            mask = mask ^ torch.diag_embed(torch.diag(mask))\n","        # compute logits\n","        anchor_dot_target = torch.einsum('bd,cd->bc', anchor, target) / self.temp\n","        # delete diag elem\n","        anchor_dot_target = anchor_dot_target - torch.diag_embed(torch.diag(anchor_dot_target))\n","        # for numerical stability\n","        logits_max, _ = torch.max(anchor_dot_target, dim=1, keepdim=True)\n","        logits = anchor_dot_target - logits_max.detach()\n","        # compute log prob\n","        exp_logits = torch.exp(logits)\n","        # mask out positives\n","        logits = logits * mask\n","        log_prob = logits - torch.log(exp_logits.sum(dim=1, keepdim=True) + 1e-12)\n","        # in case that mask.sum(1) is zero\n","        mask_sum = mask.sum(dim=1)\n","        mask_sum = torch.where(mask_sum == 0, torch.ones_like(mask_sum), mask_sum)\n","        # compute log-likelihood\n","        pos_logits = (mask * log_prob).sum(dim=1) / mask_sum.detach()\n","        loss = -1 * pos_logits.mean()\n","        return loss\n","\n","    def forward(self, outputs, targets):\n","        ce_loss = (1 - self.alpha) * self.xent_loss(outputs, targets)\n","        cl_loss = self.alpha * self.nt_xent_loss(outputs, outputs, targets)\n","        return ce_loss + cl_loss\n","\n","\n","class DualLoss(SupConLoss):\n","\n","    def __init__(self, alpha, temp):\n","        super().__init__(alpha, temp)\n","\n","    def forward(self, outputs, targets):\n","        normed_cls_feats = F.normalize(outputs['cls_feats'], dim=-1)\n","        normed_label_feats = F.normalize(outputs['label_feats'], dim=-1)\n","        normed_pos_label_feats = torch.gather(normed_label_feats, dim=1, index=targets.unsqueeze(-1).expand(-1, 1, normed_label_feats.size(-1))).squeeze(1)\n","        ce_loss = (1 - self.alpha) * self.xent_loss(outputs['predicts'], targets)\n","        cl_loss_1 = 0.5 * self.alpha * self.nt_xent_loss(normed_pos_label_feats, normed_cls_feats, targets)\n","        cl_loss_2 = 0.5 * self.alpha * self.nt_xent_loss(normed_cls_feats, normed_pos_label_feats, targets)\n","        return ce_loss + cl_loss_1 + cl_loss_2"],"metadata":{"id":"M-CiGFSuT8ED","executionInfo":{"status":"ok","timestamp":1684690056946,"user_tz":-330,"elapsed":3,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["criterion = SupConLoss(0.1, 0.1)"],"metadata":{"id":"z9UQwhJbT74_","executionInfo":{"status":"ok","timestamp":1684690062895,"user_tz":-330,"elapsed":4,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["complaint_model = complaint(hidden_size = hid_size, bitmask=bitmasks[bitmask_input], embedding=embeds[embed_input])\n","#complaint_model.to(device)\n","\n","optimizer = torch.optim.Adam(complaint_model.parameters(), lr = learning_rate)\n","\n","complaint_model.train()\n","\n","model_name = \"bert_model.pt\"\n","\n","for i in range(epochs):\n","\n","  total_loss_train = 0\n","  total_train = 0\n","\n"," \n","    \n"," \n","\n","\n","  complaint_model.load_state_dict(torch.load(model_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":862},"id":"Zz91hZnzT71c","executionInfo":{"status":"error","timestamp":1684690073063,"user_tz":-330,"elapsed":4322,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}},"outputId":"67024032-f75a-4e4c-9f2e-f60f16cedf66"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-a72bfdede8ba>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mcomplaint_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2042\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for complaint:\n\tMissing key(s) in state_dict: \"emb_model.embeddings.position_ids\", \"emb_model.embeddings.word_embeddings.weight\", \"emb_model.embeddings.position_embeddings.weight\", \"emb_model.embeddings.token_type_embeddings.weight\", \"emb_model.embeddings.LayerNorm.weight\", \"emb_model.embeddings.LayerNorm.bias\", \"emb_model.encoder.layer.0.attention.self.query.weight\", \"emb_model.encoder.layer.0.attention.self.query.bias\", \"emb_model.encoder.layer.0.attention.self.key.weight\", \"emb_model.encoder.layer.0.attention.self.key.bias\", \"emb_model.encoder.layer.0.attention.self.value.weight\", \"emb_model.encoder.layer.0.attention.self.value.bias\", \"emb_model.encoder.layer.0.attention.output.dense.weight\", \"emb_model.encoder.layer.0.attention.output.dense.bias\", \"emb_model.encoder.layer.0.attention.output.LayerNorm.weight\", \"emb_model.encoder.layer.0.attention.output.LayerNorm.bias\", \"emb_model.encoder.layer.0.intermediate.dense.weight\", \"emb_model.encoder.layer.0.intermediate.dense.bias\", \"emb_model.encoder.layer.0.output.dense.weight\", \"emb_model.encoder.layer.0.output.dense.bias\", \"emb_model.encoder.layer.0.output.LayerNorm.weight\", \"emb_model.encoder.layer.0.output.LayerNorm.bias\", \"emb_model.encoder.layer.1.attention.self.query.weight\", \"emb_model.encoder.layer.1.attention.self.query.bias\", \"emb_model.encoder.layer.1.attention.self.key.weight\", \"emb_model.encoder.layer.1.attention.self.key.bias\", \"emb_model.encoder.layer.1.attention.self.value.weight\", \"emb_model.encoder.layer.1.attention.self...\n\tUnexpected key(s) in state_dict: \"bert_model.embeddings.position_ids\", \"bert_model.embeddings.word_embeddings.weight\", \"bert_model.embeddings.position_embeddings.weight\", \"bert_model.embeddings.token_type_embeddings.weight\", \"bert_model.embeddings.LayerNorm.weight\", \"bert_model.embeddings.LayerNorm.bias\", \"bert_model.encoder.layer.0.attention.self.query.weight\", \"bert_model.encoder.layer.0.attention.self.query.bias\", \"bert_model.encoder.layer.0.attention.self.key.weight\", \"bert_model.encoder.layer.0.attention.self.key.bias\", \"bert_model.encoder.layer.0.attention.self.value.weight\", \"bert_model.encoder.layer.0.attention.self.value.bias\", \"bert_model.encoder.layer.0.attention.output.dense.weight\", \"bert_model.encoder.layer.0.attention.output.dense.bias\", \"bert_model.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert_model.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert_model.encoder.layer.0.intermediate.dense.weight\", \"bert_model.encoder.layer.0.intermediate.dense.bias\", \"bert_model.encoder.layer.0.output.dense.weight\", \"bert_model.encoder.layer.0.output.dense.bias\", \"bert_model.encoder.layer.0.output.LayerNorm.weight\", \"bert_model.encoder.layer.0.output.LayerNorm.bias\", \"bert_model.encoder.layer.1.attention.self.query.weight\", \"bert_model.encoder.layer.1.attention.self.query.bias\", \"bert_model.encoder.layer.1.attention.self.key.weight\", \"bert_model.encoder.layer.1.attention.self.key.bias\", \"bert_model.encoder.layer.1.attention.self.value.weight\", \"bert_model..."]}]},{"cell_type":"code","source":["from sklearn.metrics import *"],"metadata":{"id":"-V1gNeS0UXrf","executionInfo":{"status":"ok","timestamp":1684690091370,"user_tz":-330,"elapsed":945,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A0XyTHRFUXff","executionInfo":{"status":"ok","timestamp":1684690098402,"user_tz":-330,"elapsed":4129,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}},"outputId":"b10b447e-27cf-485b-e423-10d771a53a92"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.11.4)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"]}]},{"cell_type":"code","source":["from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryF1Score, BinaryRecall\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassF1Score, MulticlassRecall\n","\n","comp_accuracy = BinaryAccuracy()\n","comp_precision = BinaryPrecision()\n","comp_f1 = BinaryF1Score()\n","comp_recall = BinaryRecall()\n","\n","sent_accuracy = MulticlassAccuracy(num_classes=3)\n","sent_precision = MulticlassPrecision(num_classes=3)\n","sent_f1 = MulticlassF1Score(num_classes=3)\n","sent_recall = MulticlassRecall(num_classes=3)\n","\n","sev_accuracy = MulticlassAccuracy(num_classes=5)\n","sev_precision = MulticlassPrecision(num_classes=5)\n","sev_f1 = MulticlassF1Score(num_classes=5)\n","sev_recall = MulticlassRecall(num_classes=5)\n","\n","emo_accuracy = MulticlassAccuracy(num_classes=7)\n","emo_precision = MulticlassPrecision(num_classes=7)\n","emo_f1 = MulticlassF1Score(num_classes=7)\n","emo_recall = MulticlassRecall(num_classes=7)\n","\n","with torch.no_grad():\n","  if(bitmask_input == \"comp\"):\n","    for data in test_dataloader:\n","      lab_comp = data[\"label_comp\"]\n","      lab_sent = data[\"label_sent\"]\n","      lab_sev = data[\"label_sev\"]\n","      lab_emo = data[\"label_emo\"]\n","      output = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"], bitmask=bitmasks[bitmask_input])\n","      loss = criterion(output, lab_comp)\n","\n","      _, pred_comp = torch.max(output.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\")\n","  \n","  elif(bitmask_input == \"sent\"):\n","    for data in test_dataloader:\n","      lab_comp = data[\"label_comp\"]\n","      lab_sent = data[\"label_sent\"]\n","      lab_sev = data[\"label_sev\"]\n","      lab_emo = data[\"label_emo\"]\n","      out = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"], bitmask=bitmasks[bitmask_input])\n","      loss = criterion(out, lab_sent)\n","\n","      _, pred_sent = torch.max(out2.data,1)\n","\n","      sent_accuracy.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_precision.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_f1.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_recall.update(pred_sent.cpu(), lab_sent.cpu())\n","\n","    sent_test_accuracy = sent_accuracy.compute()\n","    sent_test_precision = sent_precision.compute()\n","    sent_test_f1 = sent_f1.compute()\n","    sent_test_recall = sent_recall.compute()\n","\n","    print(f\"sent_test_accuracy : {sent_test_accuracy}\")\n","    print(f\"sent_test_precision : {sent_test_precision}\")\n","    print(f\"sent_test_f1 : {sent_test_f1}\")\n","    print(f\"sent_test_recall : {sent_test_recall}\")\n","\n","  elif(bitmask_input == \"emo\"):\n","    for data in test_dataloader:\n","      lab_comp = data[\"label_comp\"]\n","      lab_sent = data[\"label_sent\"]\n","      lab_sev = data[\"label_sev\"]\n","      lab_emo = data[\"label_emo\"]\n","      out = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"], bitmask=bitmasks[bitmask_input])\n","      loss = criterion(out, lab_emo)\n","\n","      _, pred_emo = torch.max(out3.data,1)\n","\n","      emo_accuracy.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_precision.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_f1.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_recall.update(pred_emo.cpu(), lab_emo.cpu())\n","  \n","    emo_test_accuracy = emo_accuracy.compute()\n","    emo_test_precision = emo_precision.compute()\n","    emo_test_f1 = emo_f1.compute()\n","    emo_test_recall = emo_recall.compute()\n","    \n","    print(f\"emo_test_accuracy : {emo_test_accuracy}\")\n","    print(f\"emo_test_precision : {emo_test_precision}\")\n","    print(f\"emo_test_f1 : {emo_test_f1}\")\n","    print(f\"emo_test_recall : {emo_test_recall}\")\n","\n","  elif(bitmask_input == \"comp+sent\"):\n","    for data in test_dataloader:\n","      lab_comp = data[\"label_comp\"]\n","      lab_sent = data[\"label_sent\"]\n","      lab_sev = data[\"label_sev\"]\n","      lab_emo = data[\"label_emo\"]\n","      out1, out2 = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"], bitmask=bitmasks[bitmask_input])\n","      loss = criterion(out1, lab_comp) + criterion(out2, lab_sent)\n","\n","      _, pred_comp = torch.max(out1.data,1)\n","      _, pred_sent = torch.max(out2.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      sent_accuracy.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_precision.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_f1.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_recall.update(pred_sent.cpu(), lab_sent.cpu())\n","      comp_test_accuracy = comp_accuracy.compute()\n","\n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","\n","    sent_test_accuracy = sent_accuracy.compute()\n","    sent_test_precision = sent_precision.compute()\n","    sent_test_f1 = sent_f1.compute()\n","    sent_test_recall = sent_recall.compute()\n","\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\")\n","\n","    print(f\"sent_test_accuracy : {sent_test_accuracy}\")\n","    print(f\"sent_test_precision : {sent_test_precision}\")\n","    print(f\"sent_test_f1 : {sent_test_f1}\")\n","    print(f\"sent_test_recall : {sent_test_recall}\")\n","\n","\n","  elif(bitmask_input == \"comp+emo\"):\n","    for data in test_dataloader:\n","      lab_comp = data[\"label_comp\"]\n","      lab_sent = data[\"label_sent\"]\n","      lab_sev = data[\"label_sev\"]\n","      lab_emo = data[\"label_emo\"]\n","      out1, out2 = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"], bitmask=bitmasks[bitmask_input])\n","      loss = criterion(out1, lab_comp) + criterion(out2, lab_emo)\n","\n","      _, pred_comp = torch.max(out1.data,1)\n","      _, pred_emo = torch.max(out2.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      emo_accuracy.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_precision.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_f1.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_recall.update(pred_emo.cpu(), lab_emo.cpu())\n","\n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","\n","    emo_test_accuracy = emo_accuracy.compute()\n","    emo_test_precision = emo_precision.compute()\n","    emo_test_f1 = emo_f1.compute()\n","    emo_test_recall = emo_recall.compute()\n","\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\")\n","\n","    print(f\"emo_test_accuracy : {emo_test_accuracy}\")\n","    print(f\"emo_test_precision : {emo_test_precision}\")\n","    print(f\"emo_test_f1 : {emo_test_f1}\")\n","    print(f\"emo_test_recall : {emo_test_recall}\")\n","\n","  elif(bitmask_input == \"comp+sev\"):\n","    for data in test_dataloader:\n","      lab_comp = data[\"label_comp\"]\n","      lab_sent = data[\"label_sent\"]\n","      lab_sev = data[\"label_sev\"]\n","      lab_emo = data[\"label_emo\"]\n","      out1, out2 = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"], bitmask=bitmasks[bitmask_input])\n","      loss = criterion(out1, lab_comp) + criterion(out2, lab_sev)\n","\n","      _, pred_comp = torch.max(out1.data,1)\n","      _, pred_sev = torch.max(out2.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      sev_accuracy.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_precision.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_f1.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_recall.update(pred_sev.cpu(), lab_sev.cpu())\n","\n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","\n","    sev_test_accuracy = sev_accuracy.compute()\n","    sev_test_precision = sev_precision.compute()\n","    sev_test_f1 = sev_f1.compute()\n","    sev_test_recall = sev_recall.compute()\n","\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\")\n","\n","    print(f\"sev_test_accuracy : {sev_test_accuracy}\")\n","    print(f\"sev_test_precision : {sev_test_precision}\")\n","    print(f\"sev_test_f1 : {sev_test_f1}\")\n","    print(f\"sev_test_recall : {sev_test_recall}\")\n","\n","  elif(bitmask_input == \"comp+sent+emo\"):\n","    for data in test_dataloader:\n","      lab_comp = data[\"label_comp\"]\n","      lab_sent = data[\"label_sent\"]\n","      lab_sev = data[\"label_sev\"]\n","      lab_emo = data[\"label_emo\"]\n","      out1, out2, out3 = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"], bitmask=bitmasks[bitmask_input])\n","      loss = criterion(out1, lab_comp) + criterion(out2, lab_sent) + criterion(out3, lab_emo)\n","\n","      _, pred_comp = torch.max(out1.data,1)\n","      _, pred_sent = torch.max(out2.data,1)\n","      _, pred_emo = torch.max(out3.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      sent_accuracy.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_precision.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_f1.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_recall.update(pred_sent.cpu(), lab_sent.cpu())\n","\n","      emo_accuracy.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_precision.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_f1.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_recall.update(pred_emo.cpu(), lab_emo.cpu())\n","    \n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","\n","    emo_test_accuracy = emo_accuracy.compute()\n","    emo_test_precision = emo_precision.compute()\n","    emo_test_f1 = emo_f1.compute()\n","    emo_test_recall = emo_recall.compute()\n","\n","    sent_test_accuracy = sent_accuracy.compute()\n","    sent_test_precision = sent_precision.compute()\n","    sent_test_f1 = sent_f1.compute()\n","    sent_test_recall = sent_recall.compute()\n","\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\")\n","\n","    print(f\"sent_test_accuracy : {sent_test_accuracy}\")\n","    print(f\"sent_test_precision : {sent_test_precision}\")\n","    print(f\"sent_test_f1 : {sent_test_f1}\")\n","    print(f\"sent_test_recall : {sent_test_recall}\")\n","\n","    print(f\"emo_test_accuracy : {emo_test_accuracy}\")\n","    print(f\"emo_test_precision : {emo_test_precision}\")\n","    print(f\"emo_test_f1 : {emo_test_f1}\")\n","    print(f\"emo_test_recall : {emo_test_recall}\")\n","\n","  elif(bitmask_input == \"comp+sent+sev\"):\n","    for data in test_dataloader:\n","      lab_comp = data[\"label_comp\"]\n","      lab_sent = data[\"label_sent\"]\n","      lab_sev = data[\"label_sev\"]\n","      lab_emo = data[\"label_emo\"]\n","      out1, out2, out3 = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"], bitmask=bitmasks[bitmask_input])\n","      loss = criterion(out1, lab_comp) + criterion(out2, lab_sent) + criterion(out3, lab_sev)\n","\n","      _, pred_comp = torch.max(out1.data,1)\n","      _, pred_sent = torch.max(out2.data,1)\n","      _, pred_sev = torch.max(out3.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      sent_accuracy.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_precision.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_f1.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_recall.update(pred_sent.cpu(), lab_sent.cpu())\n","\n","      sev_accuracy.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_precision.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_f1.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_recall.update(pred_sev.cpu(), lab_sev.cpu())\n","\n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","\n","    sev_test_accuracy = sev_accuracy.compute()\n","    sev_test_precision = sev_precision.compute()\n","    sev_test_f1 = sev_f1.compute()\n","    sev_test_recall = sev_recall.compute()\n","\n","    sent_test_accuracy = sent_accuracy.compute()\n","    sent_test_precision = sent_precision.compute()\n","    sent_test_f1 = sent_f1.compute()\n","    sent_test_recall = sent_recall.compute()\n","\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\")\n","\n","    print(f\"sent_test_accuracy : {sent_test_accuracy}\")\n","    print(f\"sent_test_precision : {sent_test_precision}\")\n","    print(f\"sent_test_f1 : {sent_test_f1}\")\n","    print(f\"sent_test_recall : {sent_test_recall}\")\n","\n","    print(f\"sev_test_accuracy : {sev_test_accuracy}\")\n","    print(f\"sev_test_precision : {sev_test_precision}\")\n","    print(f\"sev_test_f1 : {sev_test_f1}\")\n","    print(f\"sev_test_recall : {sev_test_recall}\")\n","\n","  elif(bitmask_input == \"comp+emo+sev\"):\n","    for data in test_dataloader:\n","      lab_comp = data[\"label_comp\"]\n","      lab_sent = data[\"label_sent\"]\n","      lab_sev = data[\"label_sev\"]\n","      lab_emo = data[\"label_emo\"]\n","      out1, out2, out3 = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"], bitmask=bitmasks[bitmask_input])\n","      loss = criterion(out1, lab_comp) + criterion(out2, lab_emo) + criterion(out3, lab_sev)\n","\n","      _, pred_comp = torch.max(out1.data,1)\n","      _, pred_emo = torch.max(out2.data,1)\n","      _, pred_sev = torch.max(out3.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      emo_accuracy.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_precision.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_f1.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_recall.update(pred_emo.cpu(), lab_emo.cpu())\n","\n","      sev_accuracy.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_precision.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_f1.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_recall.update(pred_sev.cpu(), lab_sev.cpu())\n","    \n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","\n","    sev_test_accuracy = sev_accuracy.compute()\n","    sev_test_precision = sev_precision.compute()\n","    sev_test_f1 = sev_f1.compute()\n","    sev_test_recall = sev_recall.compute()\n","\n","    emo_test_accuracy = emo_accuracy.compute()\n","    emo_test_precision = emo_precision.compute()\n","    emo_test_f1 = emo_f1.compute()\n","    emo_test_recall = emo_recall.compute()\n","\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\")\n","\n","    print(f\"emo_test_accuracy : {emo_test_accuracy}\")\n","    print(f\"emo_test_precision : {emo_test_precision}\")\n","    print(f\"emo_test_f1 : {emo_test_f1}\")\n","    print(f\"emo_test_recall : {emo_test_recall}\")\n","\n","    print(f\"sev_test_accuracy : {sev_test_accuracy}\")\n","    print(f\"sev_test_precision : {sev_test_precision}\")\n","    print(f\"sev_test_f1 : {sev_test_f1}\")\n","    print(f\"sev_test_recall : {sev_test_recall}\")\n","\n","  elif(bitmask_input == \"comp+emo+sev+sent\"):\n","    for data in test_dataloader:\n","      lab_comp = data[\"label_comp\"]\n","      lab_sent = data[\"label_sent\"]\n","      lab_sev = data[\"label_sev\"]\n","      lab_emo = data[\"label_emo\"]\n","      out1, out2, out3, out4 = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"], bitmask=bitmasks[bitmask_input])\n","      loss = criterion(out1, lab_comp) + criterion(out2, lab_emo) + criterion(out3, lab_sev) + criterion(out4, lab_sent)\n","\n","      _, pred_comp = torch.max(out1.data,1)\n","      _, pred_emo = torch.max(out2.data,1)\n","      _, pred_sev = torch.max(out3.data,1)\n","      _, pred_sent = torch.max(out4.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      emo_accuracy.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_precision.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_f1.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_recall.update(pred_emo.cpu(), lab_emo.cpu())\n","\n","      sev_accuracy.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_precision.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_f1.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_recall.update(pred_sev.cpu(), lab_sev.cpu())\n","\n","      sent_accuracy.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_precision.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_f1.update(pred_sent.cpu(), lab_sent.cpu())\n","      sent_recall.update(pred_sent.cpu(), lab_sent.cpu())\n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","\n","    sev_test_accuracy = sev_accuracy.compute()\n","    sev_test_precision = sev_precision.compute()\n","    sev_test_f1 = sev_f1.compute()\n","    sev_test_recall = sev_recall.compute()\n","\n","    emo_test_accuracy = emo_accuracy.compute()\n","    emo_test_precision = emo_precision.compute()\n","    emo_test_f1 = emo_f1.compute()\n","    emo_test_recall = emo_recall.compute()\n","\n","    sent_test_accuracy = sent_accuracy.compute()\n","    sent_test_precision = sent_precision.compute()\n","    sent_test_f1 = sent_f1.compute()\n","    sent_test_recall = sent_recall.compute()\n","    \n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\")\n","\n","    print(f\"sent_test_accuracy : {sent_test_accuracy}\")\n","    print(f\"sent_test_precision : {sent_test_precision}\")\n","    print(f\"sent_test_f1 : {sent_test_f1}\")\n","    print(f\"sent_test_recall : {sent_test_recall}\")\n","\n","    print(f\"emo_test_accuracy : {emo_test_accuracy}\")\n","    print(f\"emo_test_precision : {emo_test_precision}\")\n","    print(f\"emo_test_f1 : {emo_test_f1}\")\n","    print(f\"emo_test_recall : {emo_test_recall}\")\n","\n","    print(f\"sev_test_accuracy : {sev_test_accuracy}\")\n","    print(f\"sev_test_precision : {sev_test_precision}\")\n","    print(f\"sev_test_f1 : {sev_test_f1}\")\n","    print(f\"sev_test_recall : {sev_test_recall}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lb8hs7i6UXKl","executionInfo":{"status":"ok","timestamp":1684690350450,"user_tz":-330,"elapsed":208393,"user":{"displayName":"meachine learning","userId":"02615647607236970242"}},"outputId":"a9e3610e-79fc-485b-9003-c22712655eb4"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-31-d649379ce403>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"input_ids\" : torch.tensor(self.input_ids[idx]).long(),\n","<ipython-input-31-d649379ce403>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long(),\n"]},{"output_type":"stream","name":"stdout","text":["comp_test_accuracy : 0.47527047991752625\n","comp_test_precision : 0.5007752180099487\n","comp_test_f1 : 0.4875471591949463\n","comp_test_recall : 0.4749999940395355\n","sent_test_accuracy : 0.3222194314002991\n","sent_test_precision : 0.3245837986469269\n","sent_test_f1 : 0.20248791575431824\n","sent_test_recall : 0.3222194314002991\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"34efad8341dc4da9a865b874e8a2d167":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_136c26411dec458499216481cb3f122f","IPY_MODEL_f5f09eac874f4428beee6a46e930c164","IPY_MODEL_78bd5c8f544d4e69a38f5694d1bce4a4"],"layout":"IPY_MODEL_a48e6d1cccac4e388f4262db46ec3bec"}},"136c26411dec458499216481cb3f122f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81d6acd8849e4818bc186b14e38fcfcb","placeholder":"​","style":"IPY_MODEL_d8b05aba431d489080d0f42dd1dd53b0","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"f5f09eac874f4428beee6a46e930c164":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c105c72672c24fb7a0170a9afc764eb4","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aff024647e2e4371984e148e9bdb3cad","value":231508}},"78bd5c8f544d4e69a38f5694d1bce4a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ead9659773345f895f8da4902c5f4eb","placeholder":"​","style":"IPY_MODEL_4e51b41634294c8b80621fd0fcae1339","value":" 232k/232k [00:00&lt;00:00, 1.10MB/s]"}},"a48e6d1cccac4e388f4262db46ec3bec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81d6acd8849e4818bc186b14e38fcfcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8b05aba431d489080d0f42dd1dd53b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c105c72672c24fb7a0170a9afc764eb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aff024647e2e4371984e148e9bdb3cad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ead9659773345f895f8da4902c5f4eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e51b41634294c8b80621fd0fcae1339":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4a9e6826ec0406cae65eb343738fd50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a20bfb511c2a499bac810ddaa2371dc5","IPY_MODEL_1f40fe82a571455799620f061c97694b","IPY_MODEL_d0b9b034c10e425784028eea56473c92"],"layout":"IPY_MODEL_128bfdbe47404cf8bbdff82138654ffa"}},"a20bfb511c2a499bac810ddaa2371dc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90668c3d54b641f48ad95a2587959a30","placeholder":"​","style":"IPY_MODEL_031d81ded5a64e5bb81e9e8b9bdb4734","value":"Downloading (…)okenizer_config.json: 100%"}},"1f40fe82a571455799620f061c97694b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb650d4cbc5343d09c9700b840fb9c26","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec31b21778a241309cdef34d4a7f43cd","value":28}},"d0b9b034c10e425784028eea56473c92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7cf0b8a0f1e475b91f283e661d3d36c","placeholder":"​","style":"IPY_MODEL_bfbdabbeda8544038ea8a82d7abc425e","value":" 28.0/28.0 [00:00&lt;00:00, 2.22kB/s]"}},"128bfdbe47404cf8bbdff82138654ffa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90668c3d54b641f48ad95a2587959a30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"031d81ded5a64e5bb81e9e8b9bdb4734":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb650d4cbc5343d09c9700b840fb9c26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec31b21778a241309cdef34d4a7f43cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7cf0b8a0f1e475b91f283e661d3d36c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfbdabbeda8544038ea8a82d7abc425e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d829aed0cf1744979e8c092bb808ab61":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1168f3c0765b45fea2acd667fac9a693","IPY_MODEL_bd09d71671d04d809a970f8f3b4542fd","IPY_MODEL_38ad300a04884edeabf8a2af24e46548"],"layout":"IPY_MODEL_031762f4e582439c903e5b083da4bdbd"}},"1168f3c0765b45fea2acd667fac9a693":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfdeb2f1b98143b3beabb8d6afae237c","placeholder":"​","style":"IPY_MODEL_d9e1fc6ae0f845c3b1f9c562b770a649","value":"Downloading (…)lve/main/config.json: 100%"}},"bd09d71671d04d809a970f8f3b4542fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4612599df8c24b6da2cd1823a190335f","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19d18d44bbad455e86e1992c75034084","value":570}},"38ad300a04884edeabf8a2af24e46548":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7732f08c10c948fe9b8839853d0b029e","placeholder":"​","style":"IPY_MODEL_0a363fc0629449948e437458648e22dd","value":" 570/570 [00:00&lt;00:00, 42.4kB/s]"}},"031762f4e582439c903e5b083da4bdbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfdeb2f1b98143b3beabb8d6afae237c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9e1fc6ae0f845c3b1f9c562b770a649":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4612599df8c24b6da2cd1823a190335f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19d18d44bbad455e86e1992c75034084":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7732f08c10c948fe9b8839853d0b029e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a363fc0629449948e437458648e22dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75db5e46496041468a0041246403c39d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29130bc856a54001ab4400937683dc97","IPY_MODEL_9788cfb4d9f6458bbdfe16efd53c8588","IPY_MODEL_c2f7ead9134346d699c5afaa52de717f"],"layout":"IPY_MODEL_eb572ec94c0447ddace9f7f0826663e5"}},"29130bc856a54001ab4400937683dc97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b9fbbb3ab5b4443a0276f2f1b85ad0f","placeholder":"​","style":"IPY_MODEL_dd46806bf1e44eea87d623116c719004","value":"Downloading pytorch_model.bin: 100%"}},"9788cfb4d9f6458bbdfe16efd53c8588":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3675a3226c546bca99c776cbda6e4e0","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95c0c699614a488da9a4660d511f8c36","value":440473133}},"c2f7ead9134346d699c5afaa52de717f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f950ea9b1e9b4a9cb7c803085327f7cc","placeholder":"​","style":"IPY_MODEL_f31a0c3858d04bfd9b81d39ee7bbffb9","value":" 440M/440M [00:01&lt;00:00, 272MB/s]"}},"eb572ec94c0447ddace9f7f0826663e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b9fbbb3ab5b4443a0276f2f1b85ad0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd46806bf1e44eea87d623116c719004":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3675a3226c546bca99c776cbda6e4e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95c0c699614a488da9a4660d511f8c36":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f950ea9b1e9b4a9cb7c803085327f7cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f31a0c3858d04bfd9b81d39ee7bbffb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f7ecc00b7c849e6aa691cb6fa0c5192":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2243b9cff9746148946b0a72cccb565","IPY_MODEL_0436bb0db94f4b67866c3ca08f37025b","IPY_MODEL_156292e02aee4d21988b31434941531f"],"layout":"IPY_MODEL_8a737a87594e484a9ba5b83b56d7c99b"}},"a2243b9cff9746148946b0a72cccb565":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f37cdde5a690485a83b0617fe4eebf34","placeholder":"​","style":"IPY_MODEL_cff04eb19684458481c68a2e6e9228f6","value":"Downloading (…)/main/tokenizer.json: 100%"}},"0436bb0db94f4b67866c3ca08f37025b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_22b960578b1244ffac80c5e0eafa45ba","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce78576ebfe34f8eac35e14b5f17cfc7","value":466062}},"156292e02aee4d21988b31434941531f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e07b09a5cce24f8b8731edb30dda2b59","placeholder":"​","style":"IPY_MODEL_52961b4ffcd542b3ba67c8d84969374b","value":" 466k/466k [00:00&lt;00:00, 18.0MB/s]"}},"8a737a87594e484a9ba5b83b56d7c99b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f37cdde5a690485a83b0617fe4eebf34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cff04eb19684458481c68a2e6e9228f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22b960578b1244ffac80c5e0eafa45ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce78576ebfe34f8eac35e14b5f17cfc7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e07b09a5cce24f8b8731edb30dda2b59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52961b4ffcd542b3ba67c8d84969374b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}