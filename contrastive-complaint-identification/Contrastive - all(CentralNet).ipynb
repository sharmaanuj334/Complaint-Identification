{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4061,"status":"ok","timestamp":1684683463738,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"O2bPVSPokXpd","outputId":"1e513f2e-e97f-466e-e64a-574ca0911e88"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print(device)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684683463739,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"9Yw2Qc3tkalj"},"outputs":[],"source":["import torch\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11605,"status":"ok","timestamp":1684683475341,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"Z1tPm-BGkcoS","outputId":"7eb6f12a-f905-466f-8c8c-8b19373a5010"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,\u003c0.14,\u003e=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.14.1-\u003etransformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.14.1-\u003etransformers) (4.5.0)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (1.26.15)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2.0.12)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"]}],"source":["!pip install transformers "]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1684683475342,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"QPbpFGyIkeLK"},"outputs":[],"source":["df = pd.read_csv('/content/Complaint data annotation (explain)_updated - cd (1).csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1684683475342,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"Vs8yd-Hgku7V","outputId":"9c72eb55-30ca-4c7c-e495-7df3774a8c82"},"outputs":[{"data":{"text/plain":["Index(['id', 'tweet', 'label', 'domain', 'sentiment', 'emotion', 'Severity',\n","       'Explain'],\n","      dtype='object')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.keys()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1684683475342,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"-sMinYbXkyFr","outputId":"8c12c937-5f0e-46ab-da7f-5c66531f90c1"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-2cbbb133-c37a-4b60-bf39-6a3ab9260217\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003etweet\u003c/th\u003e\n","      \u003cth\u003elabel\u003c/th\u003e\n","      \u003cth\u003edomain\u003c/th\u003e\n","      \u003cth\u003esentiment\u003c/th\u003e\n","      \u003cth\u003eemotion\u003c/th\u003e\n","      \u003cth\u003eSeverity\u003c/th\u003e\n","      \u003cth\u003eExplain\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e@FC_HELP can I return online purchases to a Ho...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eapparel\u003c/td\u003e\n","      \u003ctd\u003eNeutral\u003c/td\u003e\n","      \u003ctd\u003eother\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003ecan I return online purchases to a House of Fr...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e@FC_Help Hi - I'm writing a piece for MSN Him ...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eapparel\u003c/td\u003e\n","      \u003ctd\u003ePositive\u003c/td\u003e\n","      \u003ctd\u003eother\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eHi - I'm writing a piece for MSN Him and wonde...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e@FC_Help   i need to check my order\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eapparel\u003c/td\u003e\n","      \u003ctd\u003eNeutral\u003c/td\u003e\n","      \u003ctd\u003eother\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003ei need to check my order\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e@FC_Help I need to get in contact with someone...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003eapparel\u003c/td\u003e\n","      \u003ctd\u003eNeutral\u003c/td\u003e\n","      \u003ctd\u003eother\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003eI need to get in contact with someone regardin...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e@FC_Help How can I get a hold of you so we can...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eapparel\u003c/td\u003e\n","      \u003ctd\u003eNegative\u003c/td\u003e\n","      \u003ctd\u003eother\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eHow can I get a hold of you so we can discuss ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cbbb133-c37a-4b60-bf39-6a3ab9260217')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-2cbbb133-c37a-4b60-bf39-6a3ab9260217 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2cbbb133-c37a-4b60-bf39-6a3ab9260217');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["   id                                              tweet  label   domain  \\\n","0   1  @FC_HELP can I return online purchases to a Ho...      0  apparel   \n","1   2  @FC_Help Hi - I'm writing a piece for MSN Him ...      0  apparel   \n","2   3                @FC_Help   i need to check my order      0  apparel   \n","3   4  @FC_Help I need to get in contact with someone...      1  apparel   \n","4   5  @FC_Help How can I get a hold of you so we can...      0  apparel   \n","\n","  sentiment emotion  Severity  \\\n","0   Neutral   other         0   \n","1  Positive   other         0   \n","2   Neutral   other         0   \n","3   Neutral   other         1   \n","4  Negative   other         0   \n","\n","                                             Explain  \n","0  can I return online purchases to a House of Fr...  \n","1  Hi - I'm writing a piece for MSN Him and wonde...  \n","2                           i need to check my order  \n","3  I need to get in contact with someone regardin...  \n","4  How can I get a hold of you so we can discuss ...  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1684683475343,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"2foIDP1gmXDF"},"outputs":[],"source":["domain_dict = {\n","    \"other\" : 0,\n","    \"services\" : 1,\n","    \"random_reply\" : 2,\n","    \"software\" : 3,\n","    \"retail\" : 4,\n","    \"random_tweet\" : 5,\n","    \"transport\" : 6,\n","    \"cars\" : 7,\n","    \"food\" : 8,\n","    \"apparel\" : 9,\n","    \"electronics\" : 10\n","}\n","\n","# note to take string lower\n","senti_dict = {\n","    'negative' : 0,\n","    'positive' : 1,\n","    'neutral' : 2\n","}\n","\n","emo_dict = {\n","    'sadness' : 0, \n","    'joy' : 1, \n","    'other' : 2, \n","    'anger' : 3, \n","    'disgust' : 4, \n","    'surprise' : 5, \n","    'fear' : 6\n","}"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":861,"status":"ok","timestamp":1684683476193,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"CVP51OEwnMzu"},"outputs":[],"source":["label = []\n","domain = []\n","emotion = []\n","sentiment = []\n","severity = []\n","explain = []\n","\n","for i in range(len(df)):\n","  if (pd.isna(df['label'][i]) or pd.isna(df['domain'][i]) or pd.isna(df['emotion'][i]) or pd.isna(df['sentiment'][i]) or pd.isna(df['Severity'][i]) or pd.isna(df['Explain'][i])):\n","    continue\n","  label.append(df['label'][i])\n","  domain.append(domain_dict[df['domain'][i]])\n","  emotion.append(emo_dict[df['emotion'][i]])\n","  sentiment.append(senti_dict[(df['sentiment'][i]).lower()])\n","  severity.append(df['Severity'][i])\n","  explain.append(df['Explain'][i])"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":687,"status":"ok","timestamp":1684683476877,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"8m6kdXgPqCmj"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","label_train, label_test, domain_train, domain_test, emotion_train, emotion_test, sentiment_train, sentiment_test, severity_train, severity_test, explain_train, explain_test = train_test_split(label, domain, emotion, sentiment, severity, explain, test_size = 0.2, random_state = 42, shuffle = True)\n","label_train, label_val, domain_train, domain_val, emotion_train, emotion_val, sentiment_train, sentiment_val, severity_train, severity_val, explain_train, explain_val = train_test_split(label_train, domain_train, emotion_train, sentiment_train, severity_train, explain_train, test_size = 0.2, random_state = 42, shuffle = True)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113},"executionInfo":{"elapsed":1181,"status":"ok","timestamp":1684683478055,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"f0w5ajsPrGSm","outputId":"2ba32a39-d1a3-48d1-b09b-7bfce80f8771"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af5ba70776094491b690a287c5a1aef0","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f427bca0d69472b862f764c3c749a0e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac68cf6cf8254a4299520e9dcc25fcde","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","def preprocess_data(text):\n","  g_input_ids = []\n","  g_attention_mask = []\n","\n","  for line in text:\n","    inputs = tokenizer(line, return_tensors=\"pt\")\n","\n","    input_ids = inputs[\"input_ids\"]\n","    attention_mask = inputs[\"attention_mask\"]\n","\n","    size = input_ids.shape[1]\n","\n","    if size \u003c 60:\n","      input_ids = torch.cat((input_ids, torch.zeros(1, 60-size)), dim = 1)\n","      attention_mask = torch.cat((attention_mask, torch.zeros(1, 60-size)), dim = 1)\n","    else:\n","      input_ids = input_ids[:, :60]\n","      attention_mask = attention_mask[:, :60]\n","    \n","    # Why we use np.array()\n","    g_input_ids.append(np.array(input_ids.reshape(-1)))\n","    g_attention_mask.append(np.array(attention_mask.reshape(-1)))\n","\n","  g_input_ids = torch.tensor(g_input_ids)\n","  g_attention_mask = torch.tensor(g_attention_mask)\n","\n","  return g_input_ids, g_attention_mask"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3480,"status":"ok","timestamp":1684683481534,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"G87hIDIdyZa1","outputId":"c5fc7ef8-a885-47a7-bf4a-fe091ca69323"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-10-eb1c066b164e\u003e:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  g_input_ids = torch.tensor(g_input_ids)\n"]}],"source":["input_ids_train, attention_mask_train = preprocess_data(explain_train)\n","input_ids_val, attention_mask_val = preprocess_data(explain_val)\n","input_ids_test, attention_mask_test = preprocess_data(explain_test)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1684683481534,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"bBQt0Q6iyaHl"},"outputs":[],"source":["class Complaint_dataset():\n","  def __init__(self, input_ids, attention_mask, label, domain, emotion, sentiment, severity):\n","    self.input_ids = input_ids\n","    self.attention_mask = attention_mask\n","    self.label = label\n","    self.domain = domain\n","    self.emotion = emotion\n","    self.sentiment = sentiment\n","    self.severity = severity\n","  def __len__(self):\n","    return len(self.input_ids)\n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","      idx = idx.tolist()\n","    \n","    sample = {\n","        \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","        \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n","        \"label\" : torch.tensor(self.label[idx]).long().to(device),\n","        \"domain\" : torch.tensor(self.domain[idx]).long().to(device),\n","        \"emotion\" : torch.tensor(self.emotion[idx]).long().to(device),\n","        \"sentiment\" : torch.tensor(self.sentiment[idx]).long().to(device),\n","        \"severity\" : torch.tensor(self.severity[idx]).long().to(device)\n","    }\n","\n","    return sample"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1684683481535,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"vbPbUUxNymMu"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","complaint_train = Complaint_dataset(input_ids_train, attention_mask_train, label_train, domain_train, emotion_train, sentiment_train, severity_train)\n","train_dataloader = DataLoader(complaint_train, batch_size = 32, shuffle = False)\n","\n","complaint_val = Complaint_dataset(input_ids_val, attention_mask_val, label_val, domain_val, emotion_val, sentiment_val, severity_val)\n","val_dataloader = DataLoader(complaint_val, batch_size = 32, shuffle = False)\n","\n","complaint_test = Complaint_dataset(input_ids_test, attention_mask_test, label_test, domain_test, emotion_test, sentiment_test, severity_test)\n","test_dataloader = DataLoader(complaint_test, batch_size = 32, shuffle = False)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1684683481535,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"DknUGhh90DCl"},"outputs":[],"source":["import torch.nn as nn\n","from transformers import BertModel\n","\n","class Sentiment(nn.Module):\n","  def __init__(self, classes):\n","    super(Sentiment, self).__init__()\n","    self.senti_a = nn.Linear(768, 512).to(device)\n","    self.senti_b = nn.Linear(512, 256).to(device)\n","    self.senti_c = nn.Linear(256, classes).to(device)\n","    self.relu = nn.ReLU()\n","    self.softmax = nn.Softmax(dim = 1).to(device)\n","  def forward(self, bert_embed):\n","    senti_a = self.relu(self.senti_a(bert_embed))\n","    senti_b = self.relu(self.senti_b(senti_a))\n","    senti_out = self.softmax(self.senti_c(senti_b))\n","    return senti_a, senti_b, senti_out\n","\n","class Emotion(nn.Module):\n","  def __init__(self, classes):\n","    super(Emotion, self).__init__()\n","    self.emo_a = nn.Linear(768, 512).to(device)\n","    self.emo_b = nn.Linear(512, 256).to(device)\n","    self.emo_c = nn.Linear(256, classes).to(device)\n","    self.relu = nn.ReLU()\n","    self.softmax = nn.Softmax(dim = 1).to(device)\n","  def forward(self, bert_embed):\n","    emo_a = self.relu(self.emo_a(bert_embed))\n","    emo_b = self.relu(self.emo_b(emo_a))\n","    emo_out = self.softmax(self.emo_c(emo_b))\n","    return emo_a, emo_b, emo_out\n","\n","class Complaint(nn.Module):\n","  def __init__(self):\n","    super(Complaint, self).__init__()\n","    self.bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n","    self.senti = Sentiment(classes = 3)\n","    self.emo = Emotion(classes = 7)\n","\n","    self.senti.load_state_dict(torch.load(\"bert_sent.pt\"))\n","    self.emo.load_state_dict(torch.load(\"bert_emo.pt\"))\n","\n","    self.central_b = nn.Linear(512, 256).to(device)\n","    self.central_c = nn.Linear(256, 128).to(device)\n","    self.central_comp = nn.Linear(128, 2).to(device)\n","    self.central_sev = nn.Linear(128, 5).to(device)\n","    self.relu = nn.ReLU()\n","    self.softmax = nn.Softmax(dim = 1).to(device)\n","  def forward(self, input_ids, attention_mask):\n","    bert_embed = self.bert_model(input_ids = input_ids.to(device), attention_mask = attention_mask.to(device)).pooler_output.to(device)\n","\n","    for p in self.senti.parameters():\n","      p.require_grads = False\n","\n","    for p in self.emo.parameters():\n","      p.require_grads = False\n","\n","    senti_a, senti_b, senti_out = self.senti(bert_embed)\n","    emo_a, emo_b, emo_out = self.emo(bert_embed)\n","\n","    batch_size = emo_a.shape[0]\n","\n","    #parameters\n","    self.a = nn.ParameterList([nn.Parameter(torch.rand(1).to(device)) for i in range(4)])\n","    self.b = nn.ParameterList([nn.Parameter(torch.rand(1).to(device)) for i in range(4)])\n","    self.c = nn.ParameterList([nn.Parameter(torch.rand(1).to(device)) for i in range(4)])\n","\n","    central_a = torch.zeros(batch_size, 512).to(device)\n","    wsum_a = self.a[0].expand_as(central_a)*central_a + self.b[0].expand_as(emo_a)*emo_a + self.c[0].expand_as(senti_a)*senti_a\n","\n","    central_b = self.relu(self.central_b(wsum_a)).to(device)\n","    wsum_b = self.a[1].expand_as(central_b)*central_b + self.b[1].expand_as(emo_b)*emo_b + self.c[1].expand_as(senti_b)*senti_b\n","\n","    central_c = self.relu(self.central_c(wsum_b)).to(device)\n","\n","    # now the emo and senti are done with the output so they have their classes size\n","    # we need to concat them\n","    emo_out = torch.cat((emo_out, torch.zeros(batch_size, 128-emo_out.shape[1]).to(device)), dim = 1).to(device)\n","    senti_out = torch.cat((senti_out, torch.zeros(batch_size, 128-senti_out.shape[1]).to(device)), dim = 1).to(device)\n","    # since we have to concatenate horizontally on all the 32 samples in the batch\n","\n","    wsum_out = self.a[2].expand_as(central_c)*central_c + self.b[2].expand_as(emo_out)*emo_out + self.c[2].expand_as(senti_out)*senti_out\n","\n","    central_comp = self.softmax(self.central_comp(wsum_out)).to(device)\n","    sev_out = self.softmax(self.central_sev(wsum_out)).to(device)\n","\n","    return bert_embed, central_comp, emo_out, senti_out, sev_out\n","\n","    # need to add alphas and then do the data processing"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1684683481535,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"Dicgs0brJeDP"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","class SupConLoss(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.xent_loss = nn.CrossEntropyLoss()\n","        self.alpha = 0.5\n","        self.temp = 0.1\n","\n","    def nt_xent_loss(self, anchor, target, labels):\n","        with torch.no_grad():\n","            labels = labels.unsqueeze(-1)\n","            mask = torch.eq(labels, labels.transpose(0, 1))\n","            mask = mask ^ torch.diag_embed(torch.diag(mask))\n","\n","        anchor_dot_target = torch.einsum('bd,cd-\u003ebc', anchor, target) / self.temp\n","\n","        anchor_dot_target = anchor_dot_target - torch.diag_embed(torch.diag(anchor_dot_target))\n","\n","        logits_max, _ = torch.max(anchor_dot_target, dim=1, keepdim=True)\n","        logits = anchor_dot_target - logits_max.detach()\n","\n","        exp_logits = torch.exp(logits)\n","\n","        logits = logits * mask\n","        log_prob = logits - torch.log(exp_logits.sum(dim=1, keepdim=True) + 1e-12)\n","\n","        mask_sum = mask.sum(dim=1)\n","        mask_sum = torch.where(mask_sum == 0, torch.ones_like(mask_sum), mask_sum)\n","\n","        pos_logits = (mask * log_prob).sum(dim=1) / mask_sum.detach()\n","        loss = -1 * pos_logits.mean()\n","        return loss\n","\n","    def forward(self, output, predicted, targets):\n","        normed_output = F.normalize(output, dim=-1)\n","        ce_loss = (1 - self.alpha) * self.xent_loss(predicted, targets)\n","        cl_loss = self.alpha * self.nt_xent_loss(normed_output, normed_output, targets)\n","        return cl_loss + ce_loss"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"elapsed":9637,"status":"ok","timestamp":1684683491167,"user":{"displayName":"temp mail master","userId":"10653401467811219636"},"user_tz":-330},"id":"coPwRPE3pakp","outputId":"1bc6cd0e-5bf3-4c39-e81f-b326a5e1b598"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64b40bcd681d4269bffde91a8b0cdd0c","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["BERT_MODEL = BertModel.from_pretrained('bert-base-uncased').to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2mQQg3HCmYpP"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-12-aa0febf124e5\u003e:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","\u003cipython-input-12-aa0febf124e5\u003e:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 1\n","Validation loss : 5.244805172085762\n","Epoch : 2\n","Validation loss : 5.242507636547089\n","Epoch : 3\n","Validation loss : 5.240370005369186\n","Epoch : 4\n","Validation loss : 5.238311737775803\n","Epoch : 5\n","Validation loss : 5.236226201057434\n","Epoch : 6\n","Validation loss : 5.234210714697838\n","Epoch : 7\n","Validation loss : 5.232371240854263\n","Epoch : 8\n","Validation loss : 5.230563580989838\n","Epoch : 9\n","Validation loss : 5.22861710190773\n","Epoch : 10\n","Validation loss : 5.2267966121435165\n","Epoch : 11\n","Validation loss : 5.225081369280815\n","Epoch : 12\n","Validation loss : 5.223401352763176\n","Epoch : 13\n","Validation loss : 5.221796691417694\n","Epoch : 14\n","Validation loss : 5.220289051532745\n","Epoch : 15\n","Validation loss : 5.218810349702835\n","Epoch : 16\n","Validation loss : 5.217464968562126\n","Epoch : 17\n","Validation loss : 5.21613535284996\n","Epoch : 18\n","Validation loss : 5.214829623699188\n","Epoch : 19\n","Validation loss : 5.213618278503418\n","Epoch : 20\n","Validation loss : 5.212424859404564\n"]}],"source":["sentiment_model = Sentiment(classes = 3)\n","sentiment_model = sentiment_model.to(device)\n","sentiment_model.train()\n","\n","loss_func = SupConLoss()\n","optimizer = torch.optim.Adam(sentiment_model.parameters(), lr = 1e-5, weight_decay = 0)\n","epochs = 20\n","min_val_loss = 10\n","\n","sentiment_model.train()\n","\n","for i in range(epochs):\n","\n","  for data in train_dataloader:\n","    sentiment_model.zero_grad()\n","    senti_train = data[\"sentiment\"].to(device)\n","    EMBED = BERT_MODEL(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device)).pooler_output.to(device)\n","    _1, _2, senti_out = sentiment_model.forward(EMBED)\n","\n","    loss_train = loss_func(EMBED, senti_out, senti_train)\n","    loss_train.backward()\n","    optimizer.step()\n","\n","    sentiment_model.eval()\n","\n","    with torch.no_grad():\n","      total_loss_val = 0\n","      for data in val_dataloader:\n","        senti_val = data[\"sentiment\"].to(device)\n","        EMBED = BERT_MODEL(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device)).pooler_output.to(device)\n","        _1, _2, senti_val_out = sentiment_model(EMBED)\n","\n","        val_loss = loss_func(EMBED, senti_val_out, senti_val)\n","\n","        total_val = senti_val.size(0)\n","        total_loss_val += val_loss.item()\n","\n","      val_loss = total_loss_val / total_val\n","\n","    if ((min_val_loss-val_loss) \u003e 1e-4):\n","      min_val_loss = val_loss\n","      torch.save(sentiment_model.state_dict(), \"bert_sent.pt\")\n","\n","  print(f\"Epoch : {i+1}\")\n","  print(f\"Validation loss : {val_loss}\")\n","\n","  sentiment_model.load_state_dict(torch.load(\"bert_sent.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VlDn4HvZmYcx"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-12-aa0febf124e5\u003e:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","\u003cipython-input-12-aa0febf124e5\u003e:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 1\n","Validation loss : 6.060157120227814\n","Epoch : 2\n","Validation loss : 5.990997314453125\n","Epoch : 3\n","Validation loss : 5.92701268196106\n","Epoch : 4\n","Validation loss : 5.905016511678696\n","Epoch : 5\n","Validation loss : 5.898145079612732\n","Epoch : 6\n","Validation loss : 5.895385384559631\n","Epoch : 7\n","Validation loss : 5.893817156553268\n","Epoch : 8\n","Validation loss : 5.892601311206818\n","Epoch : 9\n","Validation loss : 5.890933811664581\n","Epoch : 10\n","Validation loss : 5.887376829981804\n","Epoch : 11\n","Validation loss : 5.88085649907589\n","Epoch : 12\n","Validation loss : 5.877245903015137\n","Epoch : 13\n","Validation loss : 5.8749192506074905\n","Epoch : 14\n","Validation loss : 5.873162791132927\n","Epoch : 15\n","Validation loss : 5.871632695198059\n","Epoch : 16\n","Validation loss : 5.8703742027282715\n","Epoch : 17\n","Validation loss : 5.869419872760773\n","Epoch : 18\n","Validation loss : 5.868600413203239\n","Epoch : 19\n","Validation loss : 5.867877870798111\n","Epoch : 20\n","Validation loss : 5.867158189415932\n"]}],"source":["emotion_model = Emotion(classes = 7)\n","emotion_model = emotion_model.to(device)\n","emotion_model.train()\n","\n","loss_func = SupConLoss()\n","optimizer = torch.optim.Adam(emotion_model.parameters(), lr = 1e-5, weight_decay = 0)\n","epochs = 20\n","min_val_loss = 10\n","\n","emotion_model.train()\n","\n","for i in range(epochs):\n","\n","  for data in train_dataloader:\n","    emotion_model.zero_grad()\n","    emo_train = data[\"emotion\"].to(device)\n","    EMBED = BERT_MODEL(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device)).pooler_output.to(device)\n","    _1, _2, emo_out = emotion_model.forward(EMBED)\n","\n","    loss_train = loss_func(EMBED, emo_out, emo_train)\n","    loss_train.backward()\n","    optimizer.step()\n","\n","    emotion_model.eval()\n","\n","    with torch.no_grad():\n","      total_loss_val = 0\n","      for data in val_dataloader:\n","        emo_val = data[\"emotion\"].to(device)\n","        EMBED = BERT_MODEL(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device)).pooler_output.to(device)\n","        _1, _2, emo_val_out = emotion_model(EMBED)\n","\n","        val_loss = loss_func(EMBED, emo_val_out, emo_val)\n","\n","        total_val = emo_val.size(0)\n","        total_loss_val += val_loss.item()\n","\n","      val_loss = total_loss_val / total_val\n","\n","    if ((min_val_loss-val_loss) \u003e 1e-4):\n","      min_val_loss = val_loss\n","      torch.save(emotion_model.state_dict(), \"bert_emo.pt\")\n","\n","  print(f\"Epoch : {i+1}\")\n","  print(f\"Validation loss : {val_loss}\")\n","\n","  emotion_model.load_state_dict(torch.load(\"bert_emo.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkXWdsQY7Qm2"},"outputs":[],"source":["complaint_model = Complaint()\n","complaint_model = complaint_model.to(device)\n","complaint_model.train()\n","\n","loss_func = SupConLoss()\n","optimizer = torch.optim.Adam(complaint_model.parameters(), lr = 1e-5, weight_decay = 0)\n","epochs = 20\n","min_val_loss = 10\n","\n","complaint_model.train()\n","\n","for i in range(epochs):\n","\n","  for data in train_dataloader:\n","    complaint_model.zero_grad()\n","    comp_train = data[\"label\"].to(device)\n","    sev_train = data[\"severity\"].to(device)\n","    embed, comp_out, emo_out, senti_out, sev_out = complaint_model.forward(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device))\n","\n","    loss_train = loss_func(embed, comp_out, comp_train) + loss_func(embed, sev_out, sev_train)\n","    loss_train.backward()\n","    optimizer.step()\n","\n","    complaint_model.eval()\n","\n","    with torch.no_grad():\n","      total_loss_val = 0\n","      for data in val_dataloader:\n","        comp_val = data[\"label\"].to(device)\n","        sev_val = data[\"severity\"].to(device)\n","        embed, comp_val_out, emo_val_out, senti_val_out, sev_val_out = complaint_model(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device))\n","\n","        val_loss = loss_func(embed, comp_val_out, comp_val) + loss_func(embed, sev_val_out, sev_val)\n","\n","        total_val = comp_val.size(0)\n","        total_loss_val += val_loss.item()\n","\n","      val_loss = total_loss_val / total_val\n","\n","    if ((min_val_loss-val_loss) \u003e 1e-4):\n","      min_val_loss = val_loss\n","      torch.save(complaint_model.state_dict(), \"bert_model.pt\")\n","\n","  print(f\"Epoch : {i+1}\")\n","  print(f\"Validation loss : {val_loss}\")\n","\n","  complaint_model.load_state_dict(torch.load(\"bert_model.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1NLvSBHHVvP"},"outputs":[],"source":["from sklearn.metrics import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vcgpzrUNKQ9"},"outputs":[],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mnt4YzqaUxgC"},"outputs":[],"source":["from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryF1Score, BinaryRecall\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassF1Score, MulticlassRecall\n","\n","comp_accuracy = BinaryAccuracy()\n","comp_precision = BinaryPrecision()\n","comp_f1 = BinaryF1Score()\n","comp_recall = BinaryRecall() \n","\n","sev_accuracy = MulticlassAccuracy(num_classes=5)\n","sev_precision = MulticlassPrecision(num_classes=5)\n","sev_f1 = MulticlassF1Score(num_classes=5)\n","sev_recall = MulticlassRecall(num_classes=5)\n","\n","emo_accuracy = MulticlassAccuracy(num_classes=7)\n","emo_precision = MulticlassPrecision(num_classes=7)\n","emo_f1 = MulticlassF1Score(num_classes=7)\n","emo_recall = MulticlassRecall(num_classes=7)\n","\n","senti_accuracy = MulticlassAccuracy(num_classes=3)\n","senti_precision = MulticlassPrecision(num_classes=3)\n","senti_f1 = MulticlassF1Score(num_classes=3)\n","senti_recall = MulticlassRecall(num_classes=3)\n","\n","with torch.no_grad():\n","    for data in test_dataloader:\n","      lab_comp = data[\"label\"]\n","      lab_emo = data[\"emotion\"]\n","      lab_senti = data[\"sentiment\"]\n","      lab_sev = data[\"severity\"]\n","\n","      comp_out, emo_out, senti_out, sev_out = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"])\n","\n","      _, pred_comp = torch.max(comp_out.data,1)\n","      _, pred_emo = torch.max(emo_out.data,1)\n","      _, pred_senti = torch.max(senti_out.data,1)\n","      _, pred_sev = torch.max(sev_out.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu()) \n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      sev_accuracy.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_precision.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_f1.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_recall.update(pred_sev.cpu(), lab_sev.cpu())\n","\n","      emo_accuracy.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_precision.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_f1.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_recall.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_test_accuracy = emo_accuracy.compute()\n","\n","      senti_accuracy.update(pred_senti.cpu(), lab_senti.cpu())\n","      senti_precision.update(pred_senti.cpu(), lab_senti.cpu())\n","      senti_f1.update(pred_senti.cpu(), lab_senti.cpu())\n","      senti_recall.update(pred_senti.cpu(), lab_senti.cpu())\n","      senti_test_accuracy = senti_accuracy.compute()\n","\n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","\n","    sev_test_accuracy = sev_accuracy.compute()\n","    sev_test_precision = sev_precision.compute()\n","    sev_test_f1 = sev_f1.compute()\n","    sev_test_recall = sev_recall.compute()\n","\n","    emo_test_accuracy = emo_accuracy.compute()\n","    emo_test_precision = emo_precision.compute()\n","    emo_test_f1 = emo_f1.compute()\n","    emo_test_recall = emo_recall.compute()\n","\n","    senti_test_accuracy = senti_accuracy.compute()\n","    senti_test_precision = senti_precision.compute()\n","    senti_test_f1 = senti_f1.compute()\n","    senti_test_recall = senti_recall.compute()\n","\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\") \n","\n","    print(f\"sev_test_accuracy : {sev_test_accuracy}\")\n","    print(f\"sev_test_precision : {sev_test_precision}\")\n","    print(f\"sev_test_f1 : {sev_test_f1}\")\n","    print(f\"sev_test_recall : {sev_test_recall}\") \n","\n","    print(f\"emo_test_accuracy : {emo_test_accuracy}\")\n","    print(f\"emo_test_precision : {emo_test_precision}\")\n","    print(f\"emo_test_f1 : {emo_test_f1}\")\n","    print(f\"emo_test_recall : {emo_test_recall}\")\n","\n","    print(f\"senti_test_accuracy : {senti_test_accuracy}\")\n","    print(f\"senti_test_precision : {senti_test_precision}\")\n","    print(f\"senti_test_f1 : {senti_test_f1}\")\n","    print(f\"senti_test_recall : {senti_test_recall}\")"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00ad8c74527848a7a75eb7fcc8c59370":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c2e0252a27a4155a9ec5f98a150444d","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09eafa59e1264f8da9063b2ccfe6075d","value":440473133}},"01bfe04dddea4a23aa455b77ec657510":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0535d06b95b04b29b7ce152baa144a55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09eafa59e1264f8da9063b2ccfe6075d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c2e0252a27a4155a9ec5f98a150444d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23dc51e25035418faf764fb901b99ff9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25f5ebe7eaf84a49b6d83463c1c1f697":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f427bca0d69472b862f764c3c749a0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d346180b3e24e3fb14dbfa267d402bb","IPY_MODEL_b97cb1178ee841c2b108bf274a66530e","IPY_MODEL_5f053e7309a140838ae7229545f002b0"],"layout":"IPY_MODEL_a3ad0f89c502483dba5670891bb108fd"}},"2f6473339d5143a3bd1db16d89b88b05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"322b1873a9ba41f29e5a79cf78d42f01":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"402d03b7461f46cf8ec3b58376447bd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e590c39649c741dbb78bc0c7f8c53687","placeholder":"​","style":"IPY_MODEL_6f2c02610bbb4a0698d000f7937d8d23","value":"Downloading (…)lve/main/config.json: 100%"}},"5d346180b3e24e3fb14dbfa267d402bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab005d6aa9204a41b7bb093b702d3b38","placeholder":"​","style":"IPY_MODEL_23dc51e25035418faf764fb901b99ff9","value":"Downloading (…)okenizer_config.json: 100%"}},"5f053e7309a140838ae7229545f002b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90b75892e02f4647a62cb0aef683b74a","placeholder":"​","style":"IPY_MODEL_86d7e5fe86214b31bcdf3f7145d3a527","value":" 28.0/28.0 [00:00\u0026lt;00:00, 1.97kB/s]"}},"5faeb9b778404a25940f4824ea4550d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62264d3a9f7d427fa4aefbecedd5b7d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64b40bcd681d4269bffde91a8b0cdd0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_725b8670819343f6ae3f05f118583c98","IPY_MODEL_00ad8c74527848a7a75eb7fcc8c59370","IPY_MODEL_737f85e67229455e93218b31e214e253"],"layout":"IPY_MODEL_d3b56d5f068c4adf8af1301a554c7dc5"}},"6716427bba6446d3b45b2cd42f328c01":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f2c02610bbb4a0698d000f7937d8d23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"725b8670819343f6ae3f05f118583c98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be6dadd191f34cadb11d5705dfcf8ee6","placeholder":"​","style":"IPY_MODEL_0535d06b95b04b29b7ce152baa144a55","value":"Downloading pytorch_model.bin: 100%"}},"73667365a2e04c38b118f87e39763c94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f6473339d5143a3bd1db16d89b88b05","placeholder":"​","style":"IPY_MODEL_5faeb9b778404a25940f4824ea4550d7","value":" 232k/232k [00:00\u0026lt;00:00, 1.79MB/s]"}},"737f85e67229455e93218b31e214e253":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79c9083690b9426ca5d58167b612d097","placeholder":"​","style":"IPY_MODEL_01bfe04dddea4a23aa455b77ec657510","value":" 440M/440M [00:01\u0026lt;00:00, 207MB/s]"}},"79c9083690b9426ca5d58167b612d097":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86d7e5fe86214b31bcdf3f7145d3a527":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87695a63290348f3a8e96f3fa701dedb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b75892e02f4647a62cb0aef683b74a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97e4a684af324f369510b48e2b5dbe7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0c597c98f304cf686de76d369078348","placeholder":"​","style":"IPY_MODEL_62264d3a9f7d427fa4aefbecedd5b7d3","value":" 570/570 [00:00\u0026lt;00:00, 43.7kB/s]"}},"a3ad0f89c502483dba5670891bb108fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab005d6aa9204a41b7bb093b702d3b38":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac68cf6cf8254a4299520e9dcc25fcde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_402d03b7461f46cf8ec3b58376447bd0","IPY_MODEL_ce28c8f18d354bd2b292d4d5407368ce","IPY_MODEL_97e4a684af324f369510b48e2b5dbe7b"],"layout":"IPY_MODEL_bfa8b381fd33416f97a258c319f3d6ad"}},"af4494d06f4b44f3b3d3c87be5f45468":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af5ba70776094491b690a287c5a1aef0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e696b1bffbc844aab5b89da8544e79f0","IPY_MODEL_bf4ee4ce8ee341e5824667eb2122b17a","IPY_MODEL_73667365a2e04c38b118f87e39763c94"],"layout":"IPY_MODEL_ce94154bc8e14a538f72fc1c3004cd7f"}},"b97cb1178ee841c2b108bf274a66530e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_322b1873a9ba41f29e5a79cf78d42f01","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25f5ebe7eaf84a49b6d83463c1c1f697","value":28}},"ba1eb015fa6641499f6c7129d0c3baa9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be6dadd191f34cadb11d5705dfcf8ee6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf4ee4ce8ee341e5824667eb2122b17a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6716427bba6446d3b45b2cd42f328c01","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af4494d06f4b44f3b3d3c87be5f45468","value":231508}},"bfa8b381fd33416f97a258c319f3d6ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c597c98f304cf686de76d369078348":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c49b29c442554a1a9c5a10278bd312d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce28c8f18d354bd2b292d4d5407368ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87695a63290348f3a8e96f3fa701dedb","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c49b29c442554a1a9c5a10278bd312d9","value":570}},"ce94154bc8e14a538f72fc1c3004cd7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b56d5f068c4adf8af1301a554c7dc5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e590c39649c741dbb78bc0c7f8c53687":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e696b1bffbc844aab5b89da8544e79f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba1eb015fa6641499f6c7129d0c3baa9","placeholder":"​","style":"IPY_MODEL_facecc1449344d8eae05301b9b37e45d","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"facecc1449344d8eae05301b9b37e45d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}