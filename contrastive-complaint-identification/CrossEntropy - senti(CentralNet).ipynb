{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4059,"status":"ok","timestamp":1684579814585,"user":{"displayName":"tmp mail 1","userId":"06282626264687502862"},"user_tz":-330},"id":"O2bPVSPokXpd","outputId":"79f510bb-e1df-4f96-87b5-ae3302ba7989"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Yw2Qc3tkalj"},"outputs":[],"source":["import torch\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11219,"status":"ok","timestamp":1684579826402,"user":{"displayName":"tmp mail 1","userId":"06282626264687502862"},"user_tz":-330},"id":"Z1tPm-BGkcoS","outputId":"4b884e59-100a-4a85-aad8-68b98ea90c51"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"]}],"source":["!pip install transformers "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPbpFGyIkeLK"},"outputs":[],"source":["df = pd.read_csv('/content/Complaint data annotation (explain)_updated - cd (1).csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vs8yd-Hgku7V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684579826403,"user_tz":-330,"elapsed":8,"user":{"displayName":"tmp mail 1","userId":"06282626264687502862"}},"outputId":"23f770dd-40f4-4256-ca6b-8e838f138a5a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['id', 'tweet', 'label', 'domain', 'sentiment', 'emotion', 'Severity',\n","       'Explain'],\n","      dtype='object')"]},"metadata":{},"execution_count":5}],"source":["df.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-sMinYbXkyFr","colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"status":"ok","timestamp":1684579826403,"user_tz":-330,"elapsed":7,"user":{"displayName":"tmp mail 1","userId":"06282626264687502862"}},"outputId":"25c0d5c0-ace4-4946-dfc6-67f63783cf1a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                              tweet  label   domain  \\\n","0   1  @FC_HELP can I return online purchases to a Ho...      0  apparel   \n","1   2  @FC_Help Hi - I'm writing a piece for MSN Him ...      0  apparel   \n","2   3                @FC_Help   i need to check my order      0  apparel   \n","3   4  @FC_Help I need to get in contact with someone...      1  apparel   \n","4   5  @FC_Help How can I get a hold of you so we can...      0  apparel   \n","\n","  sentiment emotion  Severity  \\\n","0   Neutral   other         0   \n","1  Positive   other         0   \n","2   Neutral   other         0   \n","3   Neutral   other         1   \n","4  Negative   other         0   \n","\n","                                             Explain  \n","0  can I return online purchases to a House of Fr...  \n","1  Hi - I'm writing a piece for MSN Him and wonde...  \n","2                           i need to check my order  \n","3  I need to get in contact with someone regardin...  \n","4  How can I get a hold of you so we can discuss ...  "],"text/html":["\n","  <div id=\"df-c077554b-4613-4b65-b807-a9191b5f6f54\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>label</th>\n","      <th>domain</th>\n","      <th>sentiment</th>\n","      <th>emotion</th>\n","      <th>Severity</th>\n","      <th>Explain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>@FC_HELP can I return online purchases to a Ho...</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Neutral</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>can I return online purchases to a House of Fr...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>@FC_Help Hi - I'm writing a piece for MSN Him ...</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Positive</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>Hi - I'm writing a piece for MSN Him and wonde...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>@FC_Help   i need to check my order</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Neutral</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>i need to check my order</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>@FC_Help I need to get in contact with someone...</td>\n","      <td>1</td>\n","      <td>apparel</td>\n","      <td>Neutral</td>\n","      <td>other</td>\n","      <td>1</td>\n","      <td>I need to get in contact with someone regardin...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>@FC_Help How can I get a hold of you so we can...</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Negative</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>How can I get a hold of you so we can discuss ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c077554b-4613-4b65-b807-a9191b5f6f54')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c077554b-4613-4b65-b807-a9191b5f6f54 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c077554b-4613-4b65-b807-a9191b5f6f54');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2foIDP1gmXDF"},"outputs":[],"source":["domain_dict = {\n","    \"other\" : 0,\n","    \"services\" : 1,\n","    \"random_reply\" : 2,\n","    \"software\" : 3,\n","    \"retail\" : 4,\n","    \"random_tweet\" : 5,\n","    \"transport\" : 6,\n","    \"cars\" : 7,\n","    \"food\" : 8,\n","    \"apparel\" : 9,\n","    \"electronics\" : 10\n","}\n","\n","# note to take string lower\n","senti_dict = {\n","    'negative' : 0,\n","    'positive' : 1,\n","    'neutral' : 2\n","}\n","\n","emo_dict = {\n","    'sadness' : 0, \n","    'joy' : 1, \n","    'other' : 2, \n","    'anger' : 3, \n","    'disgust' : 4, \n","    'surprise' : 5, \n","    'fear' : 6\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVP51OEwnMzu"},"outputs":[],"source":["label = []\n","domain = []\n","emotion = []\n","sentiment = []\n","severity = []\n","explain = []\n","\n","for i in range(len(df)):\n","  if (pd.isna(df['label'][i]) or pd.isna(df['domain'][i]) or pd.isna(df['emotion'][i]) or pd.isna(df['sentiment'][i]) or pd.isna(df['Severity'][i]) or pd.isna(df['Explain'][i])):\n","    continue\n","  label.append(df['label'][i])\n","  domain.append(domain_dict[df['domain'][i]])\n","  emotion.append(emo_dict[df['emotion'][i]])\n","  sentiment.append(senti_dict[(df['sentiment'][i]).lower()])\n","  severity.append(df['Severity'][i])\n","  explain.append(df['Explain'][i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8m6kdXgPqCmj"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","label_train, label_test, domain_train, domain_test, emotion_train, emotion_test, sentiment_train, sentiment_test, severity_train, severity_test, explain_train, explain_test = train_test_split(label, domain, emotion, sentiment, severity, explain, test_size = 0.2, random_state = 42, shuffle = True)\n","label_train, label_val, domain_train, domain_val, emotion_train, emotion_val, sentiment_train, sentiment_val, severity_train, severity_val, explain_train, explain_val = train_test_split(label_train, domain_train, emotion_train, sentiment_train, severity_train, explain_train, test_size = 0.2, random_state = 42, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0w5ajsPrGSm","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["91eee0fa1ee2420fa727bfd7fc539c30","754c1c61818143fd98e1258cb9d037c3","6928016f99034443b5783277e26a695b","10017bed6a574693959ba5b7bd89e1d1","36360ae9385045ad8e53abdad074e845","8a463b931d6346bbb50a6fa730683022","406baef34757437a884868da15ed8184","e6f428acf2944ba39c96c2de8be12ba3","472340bdd6c744b5966c472e8f35f177","138e8c4d87f3457f9e446827bed9ce04","534cbc6a3bf8419cbdb33131a8d0d254","ffc33ad523144b73816f7daa5c0f9e8d","dfec6f0f604c48cda4bc3508367991c5","97cde4e534c0448396a0c4cd07e04101","652f573203294163922b8353a350b060","96350b4274564d9aad3831e41ae417e7","20bb0d6e19fb4fdf8386d0f976de2b76","8a1416e78b51405b95308b523bead6d0","fd6bb6c4bafa460a9206564fa6d5505e","96dd5a8dfcd14e85b3fab37a06dd172f","2f23da16a48148b6a6fab04a03184857","d59942ad31a54ae1a54f2c14fce1df2e","bef399186d474170bc887f796e3f2e0e","126a056a4f3d489e9858cd5625ed3bcc","656010e855e842c4bb89d54e4fd87ab3","2bfab4ac0fd94087a74f7777a13db6d5","2ca444cbcb6f4dcda1ee3ccd107e91c0","86e938b3d97d4e6cb79b48e9bdb3670c","9bce9c9b4631474d95ee95473ca48e34","37f89f8f543a4a1393d887307bff0902","b7f779b062df4114bf741fac3ed6fad9","935695069466463b82216dd322cfea89","997f9e5232644b9cbdbcfbc180ff4dfb"]},"executionInfo":{"status":"ok","timestamp":1684579828870,"user_tz":-330,"elapsed":1768,"user":{"displayName":"tmp mail 1","userId":"06282626264687502862"}},"outputId":"41419c2c-f1b0-4dc5-bc09-92c3010d503b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91eee0fa1ee2420fa727bfd7fc539c30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffc33ad523144b73816f7daa5c0f9e8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bef399186d474170bc887f796e3f2e0e"}},"metadata":{}}],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","def preprocess_data(text):\n","  g_input_ids = []\n","  g_attention_mask = []\n","\n","  for line in text:\n","    inputs = tokenizer(line, return_tensors=\"pt\")\n","\n","    input_ids = inputs[\"input_ids\"]\n","    attention_mask = inputs[\"attention_mask\"]\n","\n","    size = input_ids.shape[1]\n","\n","    if size < 60:\n","      input_ids = torch.cat((input_ids, torch.zeros(1, 60-size)), dim = 1)\n","      attention_mask = torch.cat((attention_mask, torch.zeros(1, 60-size)), dim = 1)\n","    else:\n","      input_ids = input_ids[:, :60]\n","      attention_mask = attention_mask[:, :60]\n","    \n","    # Why we use np.array()\n","    g_input_ids.append(np.array(input_ids.reshape(-1)))\n","    g_attention_mask.append(np.array(attention_mask.reshape(-1)))\n","\n","  g_input_ids = torch.tensor(g_input_ids)\n","  g_attention_mask = torch.tensor(g_attention_mask)\n","\n","  return g_input_ids, g_attention_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G87hIDIdyZa1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684579831329,"user_tz":-330,"elapsed":2462,"user":{"displayName":"tmp mail 1","userId":"06282626264687502862"}},"outputId":"10802246-8d6b-4432-8879-cd089d467e01"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-eb1c066b164e>:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  g_input_ids = torch.tensor(g_input_ids)\n"]}],"source":["input_ids_train, attention_mask_train = preprocess_data(explain_train)\n","input_ids_val, attention_mask_val = preprocess_data(explain_val)\n","input_ids_test, attention_mask_test = preprocess_data(explain_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBQt0Q6iyaHl"},"outputs":[],"source":["class Complaint_dataset():\n","  def __init__(self, input_ids, attention_mask, label, domain, emotion, sentiment, severity):\n","    self.input_ids = input_ids\n","    self.attention_mask = attention_mask\n","    self.label = label\n","    self.domain = domain\n","    self.emotion = emotion\n","    self.sentiment = sentiment\n","    self.severity = severity\n","  def __len__(self):\n","    return len(self.input_ids)\n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","      idx = idx.tolist()\n","    \n","    sample = {\n","        \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","        \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n","        \"label\" : torch.tensor(self.label[idx]).long().to(device),\n","        \"domain\" : torch.tensor(self.domain[idx]).long().to(device),\n","        \"emotion\" : torch.tensor(self.emotion[idx]).long().to(device),\n","        \"sentiment\" : torch.tensor(self.sentiment[idx]).long().to(device),\n","        \"severity\" : torch.tensor(self.severity[idx]).long().to(device)\n","    }\n","\n","    return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vbPbUUxNymMu"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","complaint_train = Complaint_dataset(input_ids_train, attention_mask_train, label_train, domain_train, emotion_train, sentiment_train, severity_train)\n","train_dataloader = DataLoader(complaint_train, batch_size = 32, shuffle = False)\n","\n","complaint_val = Complaint_dataset(input_ids_val, attention_mask_val, label_val, domain_val, emotion_val, sentiment_val, severity_val)\n","val_dataloader = DataLoader(complaint_val, batch_size = 32, shuffle = False)\n","\n","complaint_test = Complaint_dataset(input_ids_test, attention_mask_test, label_test, domain_test, emotion_test, sentiment_test, severity_test)\n","test_dataloader = DataLoader(complaint_test, batch_size = 32, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DknUGhh90DCl"},"outputs":[],"source":["import torch.nn as nn\n","from transformers import BertModel\n","\n","class Sentiment(nn.Module):\n","  def __init__(self, classes):\n","    super(Sentiment, self).__init__()\n","    self.senti_a = nn.Linear(768, 512).to(device)\n","    self.senti_b = nn.Linear(512, 256).to(device)\n","    self.senti_c = nn.Linear(256, classes).to(device)\n","    self.relu = nn.ReLU()\n","    self.softmax = nn.Softmax(dim = 1).to(device)\n","  def forward(self, bert_embed):\n","    senti_a = self.relu(self.senti_a(bert_embed))\n","    senti_b = self.relu(self.senti_b(senti_a))\n","    senti_out = self.softmax(self.senti_c(senti_b))\n","    return senti_a, senti_b, senti_out\n","\n","class Complaint(nn.Module):\n","  def __init__(self):\n","    super(Complaint, self).__init__()\n","    self.bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n","    self.senti = Sentiment(classes = 3)\n","\n","    self.senti.load_state_dict(torch.load(\"bert_sent.pt\"))\n","\n","    self.central_b = nn.Linear(512, 256).to(device)\n","    self.central_c = nn.Linear(256, 128).to(device)\n","    self.central_comp = nn.Linear(128, 2).to(device)\n","    self.central_sev = nn.Linear(128, 5).to(device)\n","    self.relu = nn.ReLU()\n","    self.softmax = nn.Softmax(dim = 1).to(device)\n","  def forward(self, input_ids, attention_mask):\n","    bert_embed = self.bert_model(input_ids = input_ids.to(device), attention_mask = attention_mask.to(device)).pooler_output.to(device)\n","\n","    for p in self.senti.parameters():\n","      p.require_grads = False\n","\n","    senti_a, senti_b, senti_out = self.senti(bert_embed)\n","\n","    batch_size = senti_a.shape[0]\n","\n","    #parameters\n","    self.a = nn.ParameterList([nn.Parameter(torch.rand(1).to(device)) for i in range(4)])\n","    self.b = nn.ParameterList([nn.Parameter(torch.rand(1).to(device)) for i in range(4)])\n","    self.c = nn.ParameterList([nn.Parameter(torch.rand(1).to(device)) for i in range(4)])\n","\n","    central_a = torch.zeros(batch_size, 512).to(device)\n","    wsum_a = self.a[0].expand_as(central_a)*central_a + self.c[0].expand_as(senti_a)*senti_a\n","\n","    central_b = self.relu(self.central_b(wsum_a)).to(device)\n","    wsum_b = self.a[1].expand_as(central_b)*central_b + self.c[1].expand_as(senti_b)*senti_b\n","\n","    central_c = self.relu(self.central_c(wsum_b)).to(device)\n","\n","    # now the emo and senti are done with the output so they have their classes size\n","    # we need to concat them\n","    senti_out = torch.cat((senti_out, torch.zeros(batch_size, 128-senti_out.shape[1]).to(device)), dim = 1).to(device)\n","    # since we have to concatenate horizontally on all the 32 samples in the batch\n","\n","    wsum_out = self.a[2].expand_as(central_c)*central_c + self.c[2].expand_as(senti_out)*senti_out\n","\n","    central_comp = self.softmax(self.central_comp(wsum_out)).to(device)\n","    sev_out = self.softmax(self.central_sev(wsum_out)).to(device)\n","\n","    return central_comp, senti_out, sev_out\n","\n","    # need to add alphas and then do the data processing"]},{"cell_type":"code","source":["BERT_MODEL = BertModel.from_pretrained('bert-base-uncased').to(device)"],"metadata":{"id":"3-WiwnEhyO8y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentiment_model = Sentiment(classes = 3)\n","sentiment_model = sentiment_model.to(device)\n","sentiment_model.train()\n","\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(sentiment_model.parameters(), lr = 1e-5, weight_decay = 0)\n","epochs = 20\n","min_val_loss = 10\n","\n","sentiment_model.train()\n","\n","for i in range(epochs):\n","\n","  for data in train_dataloader:\n","    sentiment_model.zero_grad()\n","    senti_train = data[\"sentiment\"].to(device)\n","    EMBED = BERT_MODEL(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device)).pooler_output.to(device)\n","    _1, _2, senti_out = sentiment_model.forward(EMBED)\n","\n","    loss_train = loss_func(senti_out, senti_train)\n","    loss_train.backward()\n","    optimizer.step()\n","\n","    sentiment_model.eval()\n","\n","    with torch.no_grad():\n","      total_loss_val = 0\n","      for data in val_dataloader:\n","        senti_val = data[\"sentiment\"].to(device)\n","        EMBED = BERT_MODEL(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device)).pooler_output.to(device)\n","        _1, _2, senti_val_out = sentiment_model(EMBED)\n","\n","        val_loss = loss_func(senti_val_out, senti_val)\n","\n","        total_val = senti_val.size(0)\n","        total_loss_val += val_loss.item()\n","\n","      val_loss = total_loss_val / total_val\n","\n","    if ((min_val_loss-val_loss) > 1e-4):\n","      min_val_loss = val_loss\n","      torch.save(sentiment_model.state_dict(), \"bert_sent.pt\")\n","\n","  print(f\"Epoch : {i+1}\")\n","  print(f\"Validation loss : {val_loss}\")\n","\n","  sentiment_model.load_state_dict(torch.load(\"bert_sent.pt\"))"],"metadata":{"id":"jg8S8aAAlN0P","executionInfo":{"status":"error","timestamp":1684579836796,"user_tz":-330,"elapsed":5469,"user":{"displayName":"tmp mail 1","userId":"06282626264687502862"}},"outputId":"63dd9539-0269-42e3-8c32-d79b8c4afa28","colab":{"base_uri":"https://localhost:8080/","height":349}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-aa0febf124e5>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","<ipython-input-12-aa0febf124e5>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-9544539c3425>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msentiment_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msenti_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mEMBED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERT_MODEL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0m_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msenti_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'BERT_MODEL' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkXWdsQY7Qm2"},"outputs":[],"source":["complaint_model = Complaint()\n","complaint_model = complaint_model.to(device)\n","complaint_model.train()\n","\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(complaint_model.parameters(), lr = 1e-5, weight_decay = 0)\n","epochs = 20\n","min_val_loss = 10\n","\n","complaint_model.train()\n","\n","for i in range(epochs):\n","\n","  for data in train_dataloader:\n","    complaint_model.zero_grad()\n","    comp_train = data[\"label\"].to(device)\n","    sev_train = data[\"severity\"].to(device)\n","    comp_out, senti_out, sev_out = complaint_model.forward(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device))\n","\n","    loss_train = loss_func(comp_out, comp_train) + loss_func(sev_out, sev_train)\n","    loss_train.backward()\n","    optimizer.step()\n","\n","    complaint_model.eval()\n","\n","    with torch.no_grad():\n","      total_loss_val = 0\n","      for data in val_dataloader:\n","        comp_val = data[\"label\"].to(device)\n","        sev_val = data[\"severity\"].to(device)\n","        comp_val_out, senti_val_out, sev_val_out = complaint_model(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device))\n","\n","        val_loss = loss_func(comp_val_out, comp_val) + loss_func(sev_val_out, sev_val)\n","\n","        total_val = comp_val.size(0)\n","        total_loss_val += val_loss.item()\n","\n","      val_loss = total_loss_val / total_val\n","\n","    if ((min_val_loss-val_loss) > 1e-4):\n","      min_val_loss = val_loss\n","      torch.save(complaint_model.state_dict(), \"bert_model.pt\")\n","\n","  print(f\"Epoch : {i+1}\")\n","  print(f\"Validation loss : {val_loss}\")\n","\n","  complaint_model.load_state_dict(torch.load(\"bert_model.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1NLvSBHHVvP"},"outputs":[],"source":["from sklearn.metrics import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vcgpzrUNKQ9"},"outputs":[],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mnt4YzqaUxgC"},"outputs":[],"source":["from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryF1Score, BinaryRecall\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassF1Score, MulticlassRecall\n","\n","comp_accuracy = BinaryAccuracy()\n","comp_precision = BinaryPrecision()\n","comp_f1 = BinaryF1Score()\n","comp_recall = BinaryRecall() \n","\n","sev_accuracy = MulticlassAccuracy(num_classes=5)\n","sev_precision = MulticlassPrecision(num_classes=5)\n","sev_f1 = MulticlassF1Score(num_classes=5)\n","sev_recall = MulticlassRecall(num_classes=5)\n","\n","senti_accuracy = MulticlassAccuracy(num_classes=3)\n","senti_precision = MulticlassPrecision(num_classes=3)\n","senti_f1 = MulticlassF1Score(num_classes=3)\n","senti_recall = MulticlassRecall(num_classes=3)\n","\n","with torch.no_grad():\n","    for data in test_dataloader:\n","      lab_comp = data[\"label\"]\n","      lab_senti = data[\"sentiment\"]\n","      lab_sev = data[\"severity\"]\n","\n","      comp_out, senti_out, sev_out = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"])\n","\n","      _, pred_comp = torch.max(comp_out.data,1)\n","      _, pred_senti = torch.max(senti_out.data,1)\n","      _, pred_sev = torch.max(sev_out.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu()) \n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      sev_accuracy.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_precision.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_f1.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_recall.update(pred_sev.cpu(), lab_sev.cpu())\n","\n","      senti_accuracy.update(pred_senti.cpu(), lab_senti.cpu())\n","      senti_precision.update(pred_senti.cpu(), lab_senti.cpu())\n","      senti_f1.update(pred_senti.cpu(), lab_senti.cpu())\n","      senti_recall.update(pred_senti.cpu(), lab_senti.cpu())\n","      senti_test_accuracy = senti_accuracy.compute()\n","\n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","\n","    sev_test_accuracy = sev_accuracy.compute()\n","    sev_test_precision = sev_precision.compute()\n","    sev_test_f1 = sev_f1.compute()\n","    sev_test_recall = sev_recall.compute()\n","\n","    senti_test_accuracy = senti_accuracy.compute()\n","    senti_test_precision = senti_precision.compute()\n","    senti_test_f1 = senti_f1.compute()\n","    senti_test_recall = senti_recall.compute()\n","\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\") \n","\n","    print(f\"sev_test_accuracy : {sev_test_accuracy}\")\n","    print(f\"sev_test_precision : {sev_test_precision}\")\n","    print(f\"sev_test_f1 : {sev_test_f1}\")\n","    print(f\"sev_test_recall : {sev_test_recall}\") \n","\n","    print(f\"senti_test_accuracy : {senti_test_accuracy}\")\n","    print(f\"senti_test_precision : {senti_test_precision}\")\n","    print(f\"senti_test_f1 : {senti_test_f1}\")\n","    print(f\"senti_test_recall : {senti_test_recall}\")"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"91eee0fa1ee2420fa727bfd7fc539c30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_754c1c61818143fd98e1258cb9d037c3","IPY_MODEL_6928016f99034443b5783277e26a695b","IPY_MODEL_10017bed6a574693959ba5b7bd89e1d1"],"layout":"IPY_MODEL_36360ae9385045ad8e53abdad074e845"}},"754c1c61818143fd98e1258cb9d037c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a463b931d6346bbb50a6fa730683022","placeholder":"​","style":"IPY_MODEL_406baef34757437a884868da15ed8184","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"6928016f99034443b5783277e26a695b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6f428acf2944ba39c96c2de8be12ba3","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_472340bdd6c744b5966c472e8f35f177","value":231508}},"10017bed6a574693959ba5b7bd89e1d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_138e8c4d87f3457f9e446827bed9ce04","placeholder":"​","style":"IPY_MODEL_534cbc6a3bf8419cbdb33131a8d0d254","value":" 232k/232k [00:00&lt;00:00, 4.30MB/s]"}},"36360ae9385045ad8e53abdad074e845":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a463b931d6346bbb50a6fa730683022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"406baef34757437a884868da15ed8184":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6f428acf2944ba39c96c2de8be12ba3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"472340bdd6c744b5966c472e8f35f177":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"138e8c4d87f3457f9e446827bed9ce04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"534cbc6a3bf8419cbdb33131a8d0d254":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffc33ad523144b73816f7daa5c0f9e8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfec6f0f604c48cda4bc3508367991c5","IPY_MODEL_97cde4e534c0448396a0c4cd07e04101","IPY_MODEL_652f573203294163922b8353a350b060"],"layout":"IPY_MODEL_96350b4274564d9aad3831e41ae417e7"}},"dfec6f0f604c48cda4bc3508367991c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20bb0d6e19fb4fdf8386d0f976de2b76","placeholder":"​","style":"IPY_MODEL_8a1416e78b51405b95308b523bead6d0","value":"Downloading (…)okenizer_config.json: 100%"}},"97cde4e534c0448396a0c4cd07e04101":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd6bb6c4bafa460a9206564fa6d5505e","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96dd5a8dfcd14e85b3fab37a06dd172f","value":28}},"652f573203294163922b8353a350b060":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f23da16a48148b6a6fab04a03184857","placeholder":"​","style":"IPY_MODEL_d59942ad31a54ae1a54f2c14fce1df2e","value":" 28.0/28.0 [00:00&lt;00:00, 1.25kB/s]"}},"96350b4274564d9aad3831e41ae417e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20bb0d6e19fb4fdf8386d0f976de2b76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a1416e78b51405b95308b523bead6d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd6bb6c4bafa460a9206564fa6d5505e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96dd5a8dfcd14e85b3fab37a06dd172f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f23da16a48148b6a6fab04a03184857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d59942ad31a54ae1a54f2c14fce1df2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bef399186d474170bc887f796e3f2e0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_126a056a4f3d489e9858cd5625ed3bcc","IPY_MODEL_656010e855e842c4bb89d54e4fd87ab3","IPY_MODEL_2bfab4ac0fd94087a74f7777a13db6d5"],"layout":"IPY_MODEL_2ca444cbcb6f4dcda1ee3ccd107e91c0"}},"126a056a4f3d489e9858cd5625ed3bcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86e938b3d97d4e6cb79b48e9bdb3670c","placeholder":"​","style":"IPY_MODEL_9bce9c9b4631474d95ee95473ca48e34","value":"Downloading (…)lve/main/config.json: 100%"}},"656010e855e842c4bb89d54e4fd87ab3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37f89f8f543a4a1393d887307bff0902","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7f779b062df4114bf741fac3ed6fad9","value":570}},"2bfab4ac0fd94087a74f7777a13db6d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_935695069466463b82216dd322cfea89","placeholder":"​","style":"IPY_MODEL_997f9e5232644b9cbdbcfbc180ff4dfb","value":" 570/570 [00:00&lt;00:00, 43.3kB/s]"}},"2ca444cbcb6f4dcda1ee3ccd107e91c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86e938b3d97d4e6cb79b48e9bdb3670c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bce9c9b4631474d95ee95473ca48e34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37f89f8f543a4a1393d887307bff0902":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7f779b062df4114bf741fac3ed6fad9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"935695069466463b82216dd322cfea89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"997f9e5232644b9cbdbcfbc180ff4dfb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}