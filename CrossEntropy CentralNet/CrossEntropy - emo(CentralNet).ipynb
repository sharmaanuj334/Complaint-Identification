{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":493,"status":"ok","timestamp":1683964271828,"user":{"displayName":"Anuj Sharma","userId":"03599059452049964956"},"user_tz":-330},"id":"O2bPVSPokXpd","outputId":"2781d5aa-91a0-46b7-ea43-b424f38ec61f"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Yw2Qc3tkalj"},"outputs":[],"source":["import torch\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4907,"status":"ok","timestamp":1683964277829,"user":{"displayName":"Anuj Sharma","userId":"03599059452049964956"},"user_tz":-330},"id":"Z1tPm-BGkcoS","outputId":"70b2a844-ea0d-407b-fd49-68a68e3453b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"]}],"source":["!pip install transformers "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPbpFGyIkeLK"},"outputs":[],"source":["df = pd.read_csv('/content/Complaint data annotation (explain)_updated - cd (1).csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683964277830,"user":{"displayName":"Anuj Sharma","userId":"03599059452049964956"},"user_tz":-330},"id":"Vs8yd-Hgku7V","outputId":"b5e5f0d2-9941-4a21-c5a2-758ec93c63f3"},"outputs":[{"data":{"text/plain":["Index(['id', 'tweet', 'label', 'domain', 'sentiment', 'emotion', 'Severity',\n","       'Explain'],\n","      dtype='object')"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683964277830,"user":{"displayName":"Anuj Sharma","userId":"03599059452049964956"},"user_tz":-330},"id":"-sMinYbXkyFr","outputId":"2962d815-acd7-4ea6-be09-787b8f99c5cb"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-a12dba5b-5834-4f7d-97f5-d87affaf22ff\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>label</th>\n","      <th>domain</th>\n","      <th>sentiment</th>\n","      <th>emotion</th>\n","      <th>Severity</th>\n","      <th>Explain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>@FC_HELP can I return online purchases to a Ho...</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Neutral</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>can I return online purchases to a House of Fr...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>@FC_Help Hi - I'm writing a piece for MSN Him ...</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Positive</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>Hi - I'm writing a piece for MSN Him and wonde...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>@FC_Help   i need to check my order</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Neutral</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>i need to check my order</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>@FC_Help I need to get in contact with someone...</td>\n","      <td>1</td>\n","      <td>apparel</td>\n","      <td>Neutral</td>\n","      <td>other</td>\n","      <td>1</td>\n","      <td>I need to get in contact with someone regardin...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>@FC_Help How can I get a hold of you so we can...</td>\n","      <td>0</td>\n","      <td>apparel</td>\n","      <td>Negative</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>How can I get a hold of you so we can discuss ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a12dba5b-5834-4f7d-97f5-d87affaf22ff')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a12dba5b-5834-4f7d-97f5-d87affaf22ff button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a12dba5b-5834-4f7d-97f5-d87affaf22ff');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   id                                              tweet  label   domain  \\\n","0   1  @FC_HELP can I return online purchases to a Ho...      0  apparel   \n","1   2  @FC_Help Hi - I'm writing a piece for MSN Him ...      0  apparel   \n","2   3                @FC_Help   i need to check my order      0  apparel   \n","3   4  @FC_Help I need to get in contact with someone...      1  apparel   \n","4   5  @FC_Help How can I get a hold of you so we can...      0  apparel   \n","\n","  sentiment emotion  Severity  \\\n","0   Neutral   other         0   \n","1  Positive   other         0   \n","2   Neutral   other         0   \n","3   Neutral   other         1   \n","4  Negative   other         0   \n","\n","                                             Explain  \n","0  can I return online purchases to a House of Fr...  \n","1  Hi - I'm writing a piece for MSN Him and wonde...  \n","2                           i need to check my order  \n","3  I need to get in contact with someone regardin...  \n","4  How can I get a hold of you so we can discuss ...  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2foIDP1gmXDF"},"outputs":[],"source":["domain_dict = {\n","    \"other\" : 0,\n","    \"services\" : 1,\n","    \"random_reply\" : 2,\n","    \"software\" : 3,\n","    \"retail\" : 4,\n","    \"random_tweet\" : 5,\n","    \"transport\" : 6,\n","    \"cars\" : 7,\n","    \"food\" : 8,\n","    \"apparel\" : 9,\n","    \"electronics\" : 10\n","}\n","\n","# note to take string lower\n","senti_dict = {\n","    'negative' : 0,\n","    'positive' : 1,\n","    'neutral' : 2\n","}\n","\n","emo_dict = {\n","    'sadness' : 0, \n","    'joy' : 1, \n","    'other' : 2, \n","    'anger' : 3, \n","    'disgust' : 4, \n","    'surprise' : 5, \n","    'fear' : 6\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVP51OEwnMzu"},"outputs":[],"source":["label = []\n","domain = []\n","emotion = []\n","sentiment = []\n","severity = []\n","explain = []\n","\n","for i in range(len(df)):\n","  if (pd.isna(df['label'][i]) or pd.isna(df['domain'][i]) or pd.isna(df['emotion'][i]) or pd.isna(df['sentiment'][i]) or pd.isna(df['Severity'][i]) or pd.isna(df['Explain'][i])):\n","    continue\n","  label.append(df['label'][i])\n","  domain.append(domain_dict[df['domain'][i]])\n","  emotion.append(emo_dict[df['emotion'][i]])\n","  sentiment.append(senti_dict[(df['sentiment'][i]).lower()])\n","  severity.append(df['Severity'][i])\n","  explain.append(df['Explain'][i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8m6kdXgPqCmj"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","label_train, label_test, domain_train, domain_test, emotion_train, emotion_test, sentiment_train, sentiment_test, severity_train, severity_test, explain_train, explain_test = train_test_split(label, domain, emotion, sentiment, severity, explain, test_size = 0.2, random_state = 42, shuffle = True)\n","label_train, label_val, domain_train, domain_val, emotion_train, emotion_val, sentiment_train, sentiment_val, severity_train, severity_val, explain_train, explain_val = train_test_split(label_train, domain_train, emotion_train, sentiment_train, severity_train, explain_train, test_size = 0.2, random_state = 42, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0w5ajsPrGSm"},"outputs":[],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","def preprocess_data(text):\n","  g_input_ids = []\n","  g_attention_mask = []\n","\n","  for line in text:\n","    inputs = tokenizer(line, return_tensors=\"pt\")\n","\n","    input_ids = inputs[\"input_ids\"]\n","    attention_mask = inputs[\"attention_mask\"]\n","\n","    size = input_ids.shape[1]\n","\n","    if size < 60:\n","      input_ids = torch.cat((input_ids, torch.zeros(1, 60-size)), dim = 1)\n","      attention_mask = torch.cat((attention_mask, torch.zeros(1, 60-size)), dim = 1)\n","    else:\n","      input_ids = input_ids[:, :60]\n","      attention_mask = attention_mask[:, :60]\n","    \n","    # Why we use np.array()\n","    g_input_ids.append(np.array(input_ids.reshape(-1)))\n","    g_attention_mask.append(np.array(attention_mask.reshape(-1)))\n","\n","  g_input_ids = torch.tensor(g_input_ids)\n","  g_attention_mask = torch.tensor(g_attention_mask)\n","\n","  return g_input_ids, g_attention_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G87hIDIdyZa1"},"outputs":[],"source":["input_ids_train, attention_mask_train = preprocess_data(explain_train)\n","input_ids_val, attention_mask_val = preprocess_data(explain_val)\n","input_ids_test, attention_mask_test = preprocess_data(explain_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBQt0Q6iyaHl"},"outputs":[],"source":["class Complaint_dataset():\n","  def __init__(self, input_ids, attention_mask, label, domain, emotion, sentiment, severity):\n","    self.input_ids = input_ids\n","    self.attention_mask = attention_mask\n","    self.label = label\n","    self.domain = domain\n","    self.emotion = emotion\n","    self.sentiment = sentiment\n","    self.severity = severity\n","  def __len__(self):\n","    return len(self.input_ids)\n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","      idx = idx.tolist()\n","    \n","    sample = {\n","        \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","        \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n","        \"label\" : torch.tensor(self.label[idx]).long().to(device),\n","        \"domain\" : torch.tensor(self.domain[idx]).long().to(device),\n","        \"emotion\" : torch.tensor(self.emotion[idx]).long().to(device),\n","        \"sentiment\" : torch.tensor(self.sentiment[idx]).long().to(device),\n","        \"severity\" : torch.tensor(self.severity[idx]).long().to(device)\n","    }\n","\n","    return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vbPbUUxNymMu"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","complaint_train = Complaint_dataset(input_ids_train, attention_mask_train, label_train, domain_train, emotion_train, sentiment_train, severity_train)\n","train_dataloader = DataLoader(complaint_train, batch_size = 32, shuffle = False)\n","\n","complaint_val = Complaint_dataset(input_ids_val, attention_mask_val, label_val, domain_val, emotion_val, sentiment_val, severity_val)\n","val_dataloader = DataLoader(complaint_val, batch_size = 32, shuffle = False)\n","\n","complaint_test = Complaint_dataset(input_ids_test, attention_mask_test, label_test, domain_test, emotion_test, sentiment_test, severity_test)\n","test_dataloader = DataLoader(complaint_test, batch_size = 32, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DknUGhh90DCl"},"outputs":[],"source":["import torch.nn as nn\n","from transformers import BertModel\n","\n","class Emotion(nn.Module):\n","  def __init__(self, classes):\n","    super(Emotion, self).__init__()\n","    self.emo_a = nn.Linear(768, 512).to(device)\n","    self.emo_b = nn.Linear(512, 256).to(device)\n","    self.emo_c = nn.Linear(256, classes).to(device)\n","    self.relu = nn.ReLU()\n","    self.softmax = nn.Softmax(dim = 1).to(device)\n","  def forward(self, bert_embed):\n","    emo_a = self.relu(self.emo_a(bert_embed))\n","    emo_b = self.relu(self.emo_b(emo_a))\n","    emo_out = self.softmax(self.emo_c(emo_b))\n","    return emo_a, emo_b, emo_out\n","\n","class Complaint(nn.Module):\n","  def __init__(self):\n","    super(Complaint, self).__init__()\n","    self.bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n","    self.emo = Emotion(classes = 7)\n","\n","    self.emoti.load_state_dict(torch.load(\"bert_emo.pt\"))\n","\n","    self.central_b = nn.Linear(512, 256).to(device)\n","    self.central_c = nn.Linear(256, 128).to(device)\n","    self.central_comp = nn.Linear(128, 2).to(device)\n","    self.central_sev = nn.Linear(128, 5).to(device)\n","    self.relu = nn.ReLU()\n","    self.softmax = nn.Softmax(dim = 1).to(device)\n","  def forward(self, input_ids, attention_mask):\n","    bert_embed = self.bert_model(input_ids = input_ids.to(device), attention_mask = attention_mask.to(device)).pooler_output.to(device)\n","\n","    for p in self.emo.parameters():\n","      p.require_grads = False\n","\n","    emo_a, emo_b, emo_out = self.emo(bert_embed)\n","\n","    batch_size = emo_a.shape[0]\n","\n","    #parameters\n","    self.a = nn.ParameterList([nn.Parameter(torch.rand(1).to(device)) for i in range(4)])\n","    self.b = nn.ParameterList([nn.Parameter(torch.rand(1).to(device)) for i in range(4)])\n","    self.c = nn.ParameterList([nn.Parameter(torch.rand(1).to(device)) for i in range(4)])\n","\n","    central_a = torch.zeros(batch_size, 512).to(device)\n","    wsum_a = self.a[0].expand_as(central_a)*central_a + self.b[0].expand_as(emo_a)*emo_a\n","\n","    central_b = self.relu(self.central_b(wsum_a)).to(device)\n","    wsum_b = self.a[1].expand_as(central_b)*central_b + self.b[1].expand_as(emo_b)*emo_b\n","\n","    central_c = self.relu(self.central_c(wsum_b)).to(device)\n","\n","    # now the emo and senti are done with the output so they have their classes size\n","    # we need to concat them\n","    emo_out = torch.cat((emo_out, torch.zeros(batch_size, 128-emo_out.shape[1]).to(device)), dim = 1).to(device)\n","    # since we have to concatenate horizontally on all the 32 samples in the batch\n","\n","    wsum_out = self.a[2].expand_as(central_c)*central_c + self.b[2].expand_as(emo_out)*emo_out\n","\n","    central_comp = self.softmax(self.central_comp(wsum_out)).to(device)\n","    sev_out = self.softmax(self.central_sev(wsum_out)).to(device)\n","\n","    return central_comp, emo_out, sev_out\n","\n","    # need to add alphas and then do the data processing"]},{"cell_type":"code","source":["BERT_MODEL = BertModel.from_pretrained('bert-base-uncased').to(device)"],"metadata":{"id":"tCPmTtFcyQK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion_model = Emotion(classes = 7)\n","emotion_model = emotion_model.to(device)\n","emotion_model.train()\n","\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(emotion_model.parameters(), lr = 1e-5, weight_decay = 0)\n","epochs = 20\n","min_val_loss = 10\n","\n","emotion_model.train()\n","\n","for i in range(epochs):\n","\n","  for data in train_dataloader:\n","    emotion_model.zero_grad()\n","    emo_train = data[\"emotion\"].to(device)\n","    EMBED = BERT_MODEL(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device)).pooler_output.to(device)\n","    _1, _2, emo_out = emotion_model.forward(EMBED)\n","\n","    loss_train = loss_func(emo_out, emo_train)\n","    loss_train.backward()\n","    optimizer.step()\n","\n","    emotion_model.eval()\n","\n","    with torch.no_grad():\n","      total_loss_val = 0\n","      for data in val_dataloader:\n","        emo_val = data[\"emotion\"].to(device)\n","        EMBED = BERT_MODEL(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device)).pooler_output.to(device)\n","        _1, _2, emo_val_out = emotion_model(EMBED)\n","\n","        val_loss = loss_func(emo_val_out, emo_val)\n","\n","        total_val = emo_val.size(0)\n","        total_loss_val += val_loss.item()\n","\n","      val_loss = total_loss_val / total_val\n","\n","    if ((min_val_loss-val_loss) > 1e-4):\n","      min_val_loss = val_loss\n","      torch.save(emotion_model.state_dict(), \"bert_emo.pt\")\n","\n","  print(f\"Epoch : {i+1}\")\n","  print(f\"Validation loss : {val_loss}\")\n","\n","  emotion_model.load_state_dict(torch.load(\"bert_emo.pt\"))"],"metadata":{"id":"Lk5-HKYgsCWm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"wkXWdsQY7Qm2","outputId":"4df8e7fa-e1d1-4ee3-9fec-60eb2a84521d"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","<ipython-input-31-aa0febf124e5>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","<ipython-input-31-aa0febf124e5>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 1\n","Validation loss : 5.157024383544922\n","Epoch : 2\n","Validation loss : 5.105437994003296\n","Epoch : 3\n","Validation loss : 4.942259609699249\n","Epoch : 4\n","Validation loss : 4.738932743668556\n","Epoch : 5\n","Validation loss : 4.514396846294403\n","Epoch : 6\n","Validation loss : 4.340899407863617\n","Epoch : 7\n","Validation loss : 4.294280827045441\n","Epoch : 8\n","Validation loss : 4.24046166241169\n","Epoch : 9\n","Validation loss : 4.134337827563286\n","Epoch : 10\n","Validation loss : 4.162714719772339\n","Epoch : 11\n","Validation loss : 3.981364443898201\n","Epoch : 12\n","Validation loss : 4.356122747063637\n","Epoch : 13\n","Validation loss : 4.17960786819458\n","Epoch : 14\n","Validation loss : 4.0929644256830215\n","Epoch : 15\n","Validation loss : 4.337694734334946\n","Epoch : 16\n","Validation loss : 4.193168759346008\n","Epoch : 17\n","Validation loss : 4.2962735295295715\n","Epoch : 18\n","Validation loss : 4.253510341048241\n","Epoch : 19\n","Validation loss : 4.161923706531525\n","Epoch : 20\n","Validation loss : 4.238618925213814\n"]}],"source":["complaint_model = Complaint()\n","complaint_model = complaint_model.to(device)\n","complaint_model.train()\n","\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(complaint_model.parameters(), lr = 1e-5, weight_decay = 0)\n","epochs = 20\n","min_val_loss = 10\n","\n","complaint_model.train()\n","\n","for i in range(epochs):\n","\n","  for data in train_dataloader:\n","    complaint_model.zero_grad()\n","    comp_train = data[\"label\"].to(device)\n","    sev_train = data[\"severity\"].to(device)\n","    comp_out, emo_out, sev_out = complaint_model.forward(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device))\n","\n","    loss_train = loss_func(comp_out, comp_train) + loss_func(sev_out, sev_train)\n","    loss_train.backward()\n","    optimizer.step()\n","\n","    complaint_model.eval()\n","\n","    with torch.no_grad():\n","      total_loss_val = 0\n","      for data in val_dataloader:\n","        comp_val = data[\"label\"].to(device)\n","        sev_val = data[\"severity\"].to(device)\n","        comp_val_out, emo_val_out, sev_val_out = complaint_model(input_ids = data[\"input_ids\"].to(device), attention_mask = data[\"attention_mask\"].to(device))\n","\n","        val_loss = loss_func(comp_val_out, comp_val) + loss_func(sev_val_out, sev_val)\n","\n","        total_val = comp_val.size(0)\n","        total_loss_val += val_loss.item()\n","\n","      val_loss = total_loss_val / total_val\n","\n","    if ((min_val_loss-val_loss) > 1e-4):\n","      min_val_loss = val_loss\n","      torch.save(complaint_model.state_dict(), \"bert_model.pt\")\n","\n","  print(f\"Epoch : {i+1}\")\n","  print(f\"Validation loss : {val_loss}\")\n","\n","  complaint_model.load_state_dict(torch.load(\"bert_model.pt\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"h1NLvSBHHVvP"},"outputs":[],"source":["from sklearn.metrics import *"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-vcgpzrUNKQ9","outputId":"969420da-dde2-4c99-c79f-eb5ca43262b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.11.4)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.0+cu118)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Mnt4YzqaUxgC","outputId":"7ca2a192-6a9a-40de-c405-f07bd50dc1da"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-31-aa0febf124e5>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"input_ids\" : torch.tensor(self.input_ids[idx]).long().to(device),\n","<ipython-input-31-aa0febf124e5>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"attention_mask\" : torch.tensor(self.attention_mask[idx]).long().to(device),\n"]},{"name":"stdout","output_type":"stream","text":["comp_test_accuracy : 0.8623188138008118\n","comp_test_precision : 0.8611111044883728\n","comp_test_f1 : 0.7965738773345947\n","comp_test_recall : 0.7410358786582947\n","sev_test_accuracy : 0.33256080746650696\n","sev_test_precision : 0.28933557868003845\n","sev_test_f1 : 0.3090527653694153\n","sev_test_recall : 0.33256080746650696\n","emo_test_accuracy : 0.1428571492433548\n","emo_test_precision : 0.0003001200675498694\n","emo_test_f1 : 0.0005989816854707897\n","emo_test_recall : 0.1428571492433548\n"]}],"source":["from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryF1Score, BinaryRecall\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassF1Score, MulticlassRecall\n","\n","comp_accuracy = BinaryAccuracy()\n","comp_precision = BinaryPrecision()\n","comp_f1 = BinaryF1Score()\n","comp_recall = BinaryRecall() \n","\n","sev_accuracy = MulticlassAccuracy(num_classes=5)\n","sev_precision = MulticlassPrecision(num_classes=5)\n","sev_f1 = MulticlassF1Score(num_classes=5)\n","sev_recall = MulticlassRecall(num_classes=5)\n","\n","emo_accuracy = MulticlassAccuracy(num_classes=7)\n","emo_precision = MulticlassPrecision(num_classes=7)\n","emo_f1 = MulticlassF1Score(num_classes=7)\n","emo_recall = MulticlassRecall(num_classes=7)\n","\n","with torch.no_grad():\n","    for data in test_dataloader:\n","      lab_comp = data[\"label\"]\n","      lab_emo = data[\"emotion\"]\n","      lab_sev = data[\"severity\"]\n","\n","      comp_out, emo_out, sev_out = complaint_model.forward(input_ids=data[\"input_ids\"], attention_mask=data[\"attention_mask\"])\n","\n","      _, pred_comp = torch.max(comp_out.data,1)\n","      _, pred_emo = torch.max(emo_out.data,1)\n","      _, pred_sev = torch.max(sev_out.data,1)\n","\n","      comp_accuracy.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_precision.update(pred_comp.cpu(), lab_comp.cpu()) \n","      comp_f1.update(pred_comp.cpu(), lab_comp.cpu())\n","      comp_recall.update(pred_comp.cpu(), lab_comp.cpu())\n","\n","      sev_accuracy.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_precision.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_f1.update(pred_sev.cpu(), lab_sev.cpu())\n","      sev_recall.update(pred_sev.cpu(), lab_sev.cpu())\n","\n","      emo_accuracy.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_precision.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_f1.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_recall.update(pred_emo.cpu(), lab_emo.cpu())\n","      emo_test_accuracy = emo_accuracy.compute()\n","\n","    comp_test_accuracy = comp_accuracy.compute()\n","    comp_test_precision = comp_precision.compute()\n","    comp_test_f1 = comp_f1.compute()\n","    comp_test_recall = comp_recall.compute()\n","\n","    sev_test_accuracy = sev_accuracy.compute()\n","    sev_test_precision = sev_precision.compute()\n","    sev_test_f1 = sev_f1.compute()\n","    sev_test_recall = sev_recall.compute()\n","\n","    emo_test_accuracy = emo_accuracy.compute()\n","    emo_test_precision = emo_precision.compute()\n","    emo_test_f1 = emo_f1.compute()\n","    emo_test_recall = emo_recall.compute()\n","\n","    print(f\"comp_test_accuracy : {comp_test_accuracy}\")\n","    print(f\"comp_test_precision : {comp_test_precision}\")\n","    print(f\"comp_test_f1 : {comp_test_f1}\")\n","    print(f\"comp_test_recall : {comp_test_recall}\") \n","\n","    print(f\"sev_test_accuracy : {sev_test_accuracy}\")\n","    print(f\"sev_test_precision : {sev_test_precision}\")\n","    print(f\"sev_test_f1 : {sev_test_f1}\")\n","    print(f\"sev_test_recall : {sev_test_recall}\") \n","\n","    print(f\"emo_test_accuracy : {emo_test_accuracy}\")\n","    print(f\"emo_test_precision : {emo_test_precision}\")\n","    print(f\"emo_test_f1 : {emo_test_f1}\")\n","    print(f\"emo_test_recall : {emo_test_recall}\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}